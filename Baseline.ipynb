{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ztH46Nb8nrj"
   },
   "outputs": [],
   "source": [
    "#necessary import:\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_time(time):\n",
    "    return datetime.datetime.fromisoformat(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yM0dpYWA8nrl"
   },
   "outputs": [],
   "source": [
    "def load_dataset_csv(file_name : str, file_attribute_name : str) -> list:\n",
    "    #Loading the two datasets. So far we'll only be using the BPI.csv one\n",
    "    #This also parses the date column\n",
    "    df = pd.read_csv(file_name)\n",
    "    df['time:timestamp'] = df['time:timestamp'].apply(fix_time)\n",
    "    df_attr = pd.read_csv(file_attribute_name)\n",
    "    return df, df_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The current version of the tool works with the 2012 dataset!!!\n",
    "df, df_attr = load_dataset_csv('DBL 2012/BPI.csv', 'DBL 2012/BPI_attr.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kD-XDLY48nrv"
   },
   "source": [
    "Unnamed 0 is the number of the case, Unnamed 1 is the number of the step for that case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U8PN-3jC8nrw"
   },
   "outputs": [],
   "source": [
    "#Let us change the column names to the aforementioned\n",
    "df.columns = ['case_id', 'step_number', 'org:resource', 'lifecycle:transition',\n",
    "       'concept:name', 'time:timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YhZ2TMBD8nry",
    "outputId": "33a6c1af-1c4e-4ad1-e45d-6c77dd198f9c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head(10) #here let's a look at the df after some really basic pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_j1Sw4LJ8nrz"
   },
   "source": [
    "Creating a smaller df to test functions on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VMSod6OM8nr1"
   },
   "outputs": [],
   "source": [
    "#Erasing all the non-complete actions from the database:\n",
    "df = df[df['lifecycle:transition'] == 'COMPLETE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FxskLSpY8nr2"
   },
   "outputs": [],
   "source": [
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iR5XZ9m28nr4",
    "outputId": "914760f1-e275-4b62-d81c-e281bdedbb59",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#I used to suppress the output of the cell, but didn't know it also does not save any progress within this cell\n",
    "#So in order for df to update globally, we can't suppress the output unfortunately\n",
    "df.drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gb2lhEIK8nr5",
    "outputId": "91c68302-afe0-42ea-a715-5b34a5e0fbe8"
   },
   "outputs": [],
   "source": [
    "def compute_time_difference():\n",
    "    #Set the time difference column\n",
    "    #This function is places here because of the erased non-complete actions\n",
    "    df['time:time_between'] = df['time:timestamp'].diff()\n",
    "    df.loc[df['step_number'] == 0, 'time:time_between'] = pd.Timedelta(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_time_difference()\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_timestamp_data():\n",
    "    # Adds extra time related columns to the dataset to be used later\n",
    "    # 0:Monday,..., 6:Sunday\n",
    "    df['time:weekday'] = [x.weekday() for x in df['time:timestamp']]\n",
    "    df['time:hour'] = [x.hour for x in df['time:timestamp']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_timestamp_data()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n7eZKyl98nr7",
    "outputId": "8e79c86b-3bf2-4e21-f67b-4c61bdec5beb"
   },
   "outputs": [],
   "source": [
    "df['concept:name'][15:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vmNzpAQP8nr7"
   },
   "source": [
    "The baseline functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qDFBW1mu8nr9"
   },
   "outputs": [],
   "source": [
    "def creating_dict_for_next_step_stats (df : pd.DataFrame, concept_name : str) -> dict:\n",
    "    '''For an input action checks for all the possible next actions and counts their occurence'''\n",
    "    \n",
    "    dic_occurrence = {}\n",
    "    dic_total_time = {}\n",
    "    ids = list(df['case_id']) + ['editor: last id'] #Otherwise we check i+1-th position that does not exist\n",
    "    times = list(df['time:time_between']) + [pd.Timedelta(0)] #Otherwise we check i+1-th position that does not exist\n",
    "    names = df['concept:name']\n",
    "    df_concept = df[names == concept_name]\n",
    "    \n",
    "    for i, row in df_concept.iterrows():\n",
    "        if (ids[i] == ids[i+1]): #an instance of the same case\n",
    "            if (names[i+1] not in dic_occurrence):\n",
    "                dic_occurrence[names[i+1]] = 1\n",
    "                dic_total_time[names[i+1]] = times[i+1]\n",
    "            else:\n",
    "                dic_occurrence[names[i+1]] += 1\n",
    "                dic_total_time[names[i+1]] += times[i+1]\n",
    "        else: #the last instance of the case\n",
    "            if ('editor: close_case' not in dic_occurrence):\n",
    "                dic_occurrence['editor: close_case'] = 1\n",
    "                dic_total_time['editor: close_case'] = times[i+1]\n",
    "            else:\n",
    "                dic_occurrence['editor: close_case'] += 1\n",
    "                dic_total_time['editor: close_case'] += times[i+1]\n",
    "    \n",
    "    #Compute average time\n",
    "    dic_avg_time = {}\n",
    "    for key in dic_total_time:\n",
    "        dic_avg_time[key] = dic_total_time[key] / dic_occurrence[key]\n",
    "        \n",
    "    return(dic_occurrence, dic_avg_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Y0Ev_cr8nr9",
    "outputId": "ef558320-399a-4a2d-a324-923a56d6cd46"
   },
   "outputs": [],
   "source": [
    "creating_dict_for_next_step_stats(df, 'A_SUBMITTED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bJCw6a1W8nr_"
   },
   "outputs": [],
   "source": [
    "def choosing_next_action(dic : dict):\n",
    "    '''Finds the max value of the input dict and returns the key of the max value'''\n",
    "    \n",
    "    max_key = max(dic, key=dic.get)\n",
    "    return(max_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hjjsb7iz8nsA",
    "outputId": "801c6101-8219-4cb2-e8cc-628f7fc888da"
   },
   "outputs": [],
   "source": [
    "choosing_next_action({'A_PARTLYSUBMITTED': 910, \"wow\": 21, \"not_wow\": 37})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lRnL2Tm38nsB"
   },
   "outputs": [],
   "source": [
    "def cycles_shortcut(actions : list, concept_name : str, max_length : int) -> list or bool:\n",
    "    '''For saving the operating time, we will try to terminate the baseline early if we get into a loop\n",
    "    max_length is the longest_trace parameter'''\n",
    "    \n",
    "    if(concept_name in actions): #the action has already been done\n",
    "        if(actions[-1] == concept_name): #and it's the most recent action (self-loop)\n",
    "            while(len(actions) < max_length): #filling the rest of the list with the current action if we're in a self-loop\n",
    "                actions.append(concept_name)\n",
    "        \n",
    "        else: #it is not the most recent action\n",
    "            placement = actions.index(concept_name) #locating the index of the \"duplicate\"\n",
    "            aid_array = actions[placement:] #copying the values\n",
    "            print(\"aid_array = \", aid_array)\n",
    "            \n",
    "            actions = actions + [0] * (max_length-len(actions)) #making [x, y, z, x] into [x, y, z, x, 0, 0, 0, ...]\n",
    "            print(\"actions = \", actions)\n",
    "            \n",
    "            for i in range(placement+1, max_length): #iterating only over all the indices of 0's in actions\n",
    "                actions[i] = aid_array[(i-placement)%len(aid_array)] #copying the list's values over and over again\n",
    "        \n",
    "        return(actions) #This return has to be then the return of the iterated_expected_actions\n",
    "    \n",
    "    else:\n",
    "        return(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bCIFIAnV8nsC",
    "outputId": "26bf5d8c-85e5-424e-9b31-475c012a165e"
   },
   "outputs": [],
   "source": [
    "cycles_shortcut([2, 1, 3, 7], 3, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PnDMr_Gw8nsD"
   },
   "outputs": [],
   "source": [
    "def iterating_expected_actions(df : pd.DataFrame, concept_name : str, n : int) -> list:\n",
    "    '''concept_name is the starting point (first action)\n",
    "    n is the length of the longest trace ever observed\n",
    "    It is stored in lonest_trace but for runtime reasons, use n so far'''\n",
    "    \n",
    "    longest_trace = max(df['step_number']) #finding the longest trace in the database (nr of steps)\n",
    "    #note that we determine this AFTER deleting some rows with uncomplete steps. We should be running this on full df\n",
    "    \n",
    "    i = 0\n",
    "    actions = [concept_name] #Here is the list that will store all the subsequent actions the algorithm decices to perform\n",
    "    while (i < n): #terminate if we are exceeding the max number of steps\n",
    "        wow = creating_dict_for_next_step_stats(df, concept_name)[0] #list all possible options\n",
    "        concept_name = choosing_next_action(wow) #Choose the most commonly used option\n",
    "        \n",
    "        if(cycles_shortcut(actions, concept_name, n) != False): #Checks if we are stuck in a loop\n",
    "            print(\"we are stuck in a loop\")\n",
    "            return(cycles_shortcut(actions, concept_name, n))\n",
    "        \n",
    "        if(concept_name == 'editor: close_case'): #If it is the \"terminate\" option - terminate\n",
    "            break\n",
    "        actions.append(concept_name) #Add the action to the list\n",
    "        i += 1\n",
    "    \n",
    "    actions.append('editor: close_case')\n",
    "    print('i = ', i, \"n = \", n)\n",
    "    \n",
    "    return(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_expected_events(df : pd.DataFrame) -> list:\n",
    "    all_events = df['concept:name'].unique()\n",
    "    next_event_name_dic = {'editor: close_case': 'editor: close_case'}\n",
    "    next_event_duration_dic = {'editor: close_case': pd.Timedelta(0)}\n",
    "    for event in all_events:\n",
    "        next_step_stats = creating_dict_for_next_step_stats(df, event)\n",
    "        wow = next_step_stats[0] #list all possible options\n",
    "        concept_name = choosing_next_action(wow) #Choose the most commonly used option\n",
    "        next_event_name_dic[event] = concept_name\n",
    "        next_event_duration_dic[event] = next_step_stats[1][concept_name]\n",
    "    return next_event_name_dic, next_event_duration_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get list of all expected next events and the expected time till that next event\n",
    "all_expected_events = add_expected_events(df)\n",
    "all_expected_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add column to dataframe with expected next events and times\n",
    "df['expect:next_event'] = df['concept:name'].map(all_expected_events[0])\n",
    "df['expect:next_time'] = df['concept:name'].map(all_expected_events[1]) + df['time:timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('BPI_with_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0OO4guwW8nsD",
    "outputId": "aa6c2d55-1e81-42c9-ae26-16595a5096be"
   },
   "outputs": [],
   "source": [
    "iterating_expected_actions(df, 'A_SUBMITTED', 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QNOh8Gv18nsF"
   },
   "source": [
    "## Here let us try to measure the performance of the baseline\n",
    "\n",
    "### We will be determining its running time vs. input size to make a graph of it and use for the poster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4x-hphJe8nsF",
    "outputId": "e37ccc1a-f1ff-4e6a-dc00-1993a52018e7"
   },
   "outputs": [],
   "source": [
    "limits = [50, 100, 200, 500, 1000, 2000, 5000, 10000, 20000, 50000, 100000]\n",
    "runtimes = [0] * len(limits)\n",
    "\n",
    "for i in range(0, len(limits)):\n",
    "    print(i)\n",
    "    df_small = df[:limits[i]]\n",
    "    time_start = time.time()\n",
    "    iterating_expected_actions(df_small, 'A_SUBMITTED', 15)\n",
    "    time_end = time.time()\n",
    "    runtimes[i] = time_end-time_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zqqlJVtA8nsG",
    "outputId": "30250728-72da-4174-c0cb-14b95744565a"
   },
   "outputs": [],
   "source": [
    "runtimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s5tBNZ-Y8nsH"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MI7bhmqp8nsI",
    "outputId": "1b1ee766-42a3-40ac-f40e-f3d49b436385"
   },
   "outputs": [],
   "source": [
    "wow = plt.figure(figsize=(7.5, 5))\n",
    "plt.scatter(x = limits, y=runtimes, color = '#AB3334')\n",
    "plt.title('Runtime of the baseline algorithm (log scale)', fontsize = 16)\n",
    "plt.ylabel('Operating time [log(s)]', fontsize = 13)\n",
    "plt.xlabel('Input size [log(n)]', fontsize = 13)\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale('log')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NRYYOj5F8nsK",
    "outputId": "e4dfe4c0-fd34-4f24-edff-8b171fb98e41"
   },
   "outputs": [],
   "source": [
    "wow2 = plt.figure(figsize=(7.5, 5))\n",
    "plt.scatter(x = limits, y=runtimes, color = '#420CDA')\n",
    "plt.title('Runtime of the baseline algorithm', fontsize = 16)\n",
    "plt.ylabel('Operating time [s]', fontsize = 13)\n",
    "plt.xlabel('Input size [n]', fontsize = 13)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fX9_jcir8nsK",
    "outputId": "89de7674-f85f-48dd-f25e-702d9df9c811"
   },
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(18,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o_DnkIxA8nsL"
   },
   "outputs": [],
   "source": [
    "ax1.scatter(x = limits, y=runtimes, color = '#420CDA')\n",
    "ax1.set_title('Runtime of the baseline algorithm', fontsize = 16)\n",
    "ax1.set_xlabel('Input size [n]', fontsize = 13)\n",
    "ax1.set_ylabel('Operating time [s]', fontsize = 13)\n",
    "\n",
    "ax2.scatter(x = limits, y=runtimes, color = '#AB3334')\n",
    "ax2.set_title('Runtime of the baseline algorithm (log scale)', fontsize = 16)\n",
    "ax2.set_ylabel('Operating time [log(s)]', fontsize = 13)\n",
    "ax2.set_xlabel('Input size [log(n)]', fontsize = 13)\n",
    "ax2.set_xscale(\"log\")\n",
    "ax2.set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oXTAKlbg8nsM",
    "outputId": "0783e546-bb71-4bae-9262-6972f6f4bec5"
   },
   "outputs": [],
   "source": [
    "f"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "BaselineUpdated.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
