{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import datetime\n",
    "import random\n",
    "import time\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XES TO CSV\n",
    "xesToCsv_BPI = xes_importer.apply(\"Datasets/BPI_Challenge_2012.xes\")\n",
    "\n",
    "xesToCsv_listo = []\n",
    "xesToCsv_dic = {'no': -1}\n",
    "xesToCsv_prev_attr = 'no'\n",
    "xesToCsv_counter = 0\n",
    "xesToCsv_cur_attr = 'no'\n",
    "\n",
    "for i in range(0, len(xesToCsv_BPI)):\n",
    "\n",
    "    for j in range(0, len(xesToCsv_BPI[i])):\n",
    "        xesToCsv_attr_list = list(xesToCsv_BPI[i][j])\n",
    "    \n",
    "        for k in range(0, len(xesToCsv_attr_list)):\n",
    "            xesToCsv_prev_attr = xesToCsv_cur_attr\n",
    "            xesToCsv_cur_attr = xesToCsv_attr_list[k]\n",
    "\n",
    "            if xesToCsv_cur_attr not in xesToCsv_listo:\n",
    "                xesToCsv_value = xesToCsv_dic[xesToCsv_prev_attr] + 1\n",
    "            \n",
    "                for key in xesToCsv_dic:\n",
    "                    if xesToCsv_dic[key] >= xesToCsv_value:\n",
    "                        xesToCsv_dic[key] += 1\n",
    "            \n",
    "                xesToCsv_dic[xesToCsv_cur_attr] = xesToCsv_value\n",
    "                xesToCsv_listo.insert(xesToCsv_value, xesToCsv_cur_attr)\n",
    "        \n",
    "        xesToCsv_cur_attr = 'no'\n",
    "        \n",
    "        \n",
    "xesToCsv_chain = []\n",
    "xesToCsv_event = []\n",
    "\n",
    "for i in range(0, len(xesToCsv_BPI)):\n",
    "    for j in range(0, len(xesToCsv_BPI[i])):\n",
    "        xesToCsv_chain.append(i)\n",
    "        xesToCsv_event.append(j)\n",
    "        \n",
    "xesToCsv_df_BPI= pd.DataFrame(index=[np.array(xesToCsv_chain), np.array(xesToCsv_event)], columns = xesToCsv_listo)\n",
    "\n",
    "for i in range(0, len(xesToCsv_BPI)):\n",
    "    \n",
    "    for j in range(0, len(xesToCsv_BPI[i])):\n",
    "\n",
    "        xesToCsv_attr = xesToCsv_BPI[i][j]\n",
    "        \n",
    "        for a in xesToCsv_attr:\n",
    "            xesToCsv_df_BPI.loc[(i, j), a] = xesToCsv_attr[a]\n",
    "            \n",
    "            \n",
    "xesToCsv_df_BPI.to_csv('Datasets/BPI.csv')\n",
    "\n",
    "xesToCsv_attr_listo = []\n",
    "xesToCsv_attr_dic = {'no': -1}\n",
    "xesToCsv_prev_attr = 'no'\n",
    "xesToCsv_counter = 0\n",
    "xesToCsv_cur_attr = 'no'\n",
    "\n",
    "for i in range(0, len(xesToCsv_BPI)):\n",
    "    xesToCsv_attr_list = list(xesToCsv_BPI[i].attributes)\n",
    "    \n",
    "    for k in range(0, len(xesToCsv_attr_list)):\n",
    "        xesToCsv_prev_attr = xesToCsv_cur_attr\n",
    "        xesToCsv_cur_attr = xesToCsv_attr_list[k]\n",
    "\n",
    "        if xesToCsv_cur_attr not in xesToCsv_attr_listo:\n",
    "            xesToCsv_value = xesToCsv_attr_dic[xesToCsv_prev_attr] + 1\n",
    "            \n",
    "            for key in xesToCsv_attr_dic:\n",
    "                if xesToCsv_attr_dic[key] >= xesToCsv_value:\n",
    "                    xesToCsv_attr_dic[key] += 1\n",
    "            \n",
    "            xesToCsv_attr_dic[xesToCsv_cur_attr] = xesToCsv_value\n",
    "            xesToCsv_attr_listo.insert(xesToCsv_value, xesToCsv_cur_attr)\n",
    "    \n",
    "    xesToCsv_cur_attr = 'no'\n",
    "    \n",
    "    \n",
    "xesToCsv_attr_chain = []\n",
    "\n",
    "for i in range(0, len(xesToCsv_BPI)):\n",
    "    xesToCsv_attr_chain.append(i)\n",
    "    \n",
    "\n",
    "xesToCsv_df_BPI_attr = pd.DataFrame(index = [np.array(xesToCsv_attr_chain)], columns = xesToCsv_attr_listo)\n",
    "\n",
    "\n",
    "for i in range(0, len(xesToCsv_BPI)):\n",
    "\n",
    "    xesToCsv_attr = xesToCsv_BPI[i].attributes\n",
    "    \n",
    "    for a in xesToCsv_attr:\n",
    "        xesToCsv_df_BPI_attr.loc[i, a] = xesToCsv_attr[a]\n",
    "        \n",
    "xesToCsv_df_BPI_attr.to_csv('Datasets/BPI_attr.csv')\n",
    "\n",
    "if 'Unnamed: 0' in xesToCsv_df_BPI.columns:\n",
    "    xesToCsv_df_BPI = xesToCsv_df_BPI.rename(columns={'Unnamed: 0': 'chain', 'Unnamed: 1': 'event'})\n",
    "    xesToCsv_df_BPI = xesToCsv_df_BPI.set_index(['chain', 'event'])\n",
    "    xesToCsv_df_BPI_attr = xesToCsv_df_BPI_attr.rename(columns={'Unnamed: 0': 'chain'})\n",
    "    xesToCsv_df_BPI_attr = xesToCsv_df_BPI_attr.set_index('chain')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Load\n",
    "\n",
    "def fix_time(time):\n",
    "    return datetime.datetime.fromisoformat(time)\n",
    "\n",
    "def load_data(BPI = 'BPI.csv', BPI_attr = 'BPI_attr.csv',  data2012 = False):\n",
    "    df_BPI = pd.read_csv(BPI)\n",
    "    df_BPI_attr = pd.read_csv(BPI_attr)\n",
    "    \n",
    "    if 'Unnamed: 0' in df_BPI.columns:\n",
    "        df_BPI = df_BPI.rename(columns={'Unnamed: 0': 'chain', 'Unnamed: 1': 'event'})\n",
    "        df_BPI = df_BPI.set_index(['chain', 'event'])\n",
    "        df_BPI_attr = df_BPI_attr.rename(columns={'Unnamed: 0': 'chain'})\n",
    "        df_BPI_attr = df_BPI_attr.set_index('chain')\n",
    "    \n",
    "    df_BPI['time:timestamp'] = df_BPI['time:timestamp'].apply(fix_time)\n",
    "\n",
    "    if data2012:\n",
    "        df_BPI_attr['REG_DATE'] = df_BPI_attr['REG_DATE'].apply(fix_time)\n",
    "    \n",
    "    df_BPI['time:weekday'] = [x.weekday() for x in df_BPI['time:timestamp']]\n",
    "    df_BPI['time:hour'] = [x.hour for x in df_BPI['time:timestamp']]\n",
    "    return df_BPI, df_BPI_attr\n",
    "\n",
    "def load_data_xes(data):\n",
    "    BPI = xes_importer.apply(data)\n",
    "    \n",
    "df, df_attr = load_data(BPI = 'Datasets/BPI_2012.csv', BPI_attr = 'Datasets/BPI_attr_2012.csv', data2012 = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split Data\n",
    "\n",
    "splitData_df = df\n",
    "splitData_df = splitData_df.rename(columns={'Unnamed: 0': 'case_id', 'Unnamed: 1': 'step_number'})\n",
    "    \n",
    "splitData_df_attr = df_attr\n",
    "splitData_df_attr = splitData_df_attr.rename(columns={'Unnamed: 0': 'case_id'})\n",
    "\n",
    "splitData_limit_date = datetime.datetime(2012, 2, 3, 1, 1, 1, 633000, tzinfo=datetime.timezone(datetime.timedelta(seconds=7200)))\n",
    "\n",
    "#training data_set\n",
    "splitData_df_train = splitData_df\n",
    "#df_train = pd.DataFrame(columns = (df.columns))\n",
    "\n",
    "splitData_listo = []\n",
    "\n",
    "for i in tqdm(range(0, 13087)):\n",
    "    if splitData_df[splitData_df['case_id'] == i].iloc[-1]['time:timestamp'] > splitData_limit_date:\n",
    "        splitData_listo.append(i)\n",
    "\n",
    "for i in tqdm(range(0, len(splitData_listo))):\n",
    "    splitData_df_train = splitData_df_train.drop(splitData_df_train[splitData_df_train['case_id'] == splitData_listo[i]].index)\n",
    "\n",
    "#for i in tqdm(range(0, len(listo))):\n",
    "    #df_train = df_train.append(df[df['case_id'] == listo[i]])\n",
    "\n",
    "splitData_df_train = splitData_df_train.reset_index(drop = True)\n",
    "\n",
    "#testing data_set\n",
    "splitData_df_test = pd.DataFrame(columns = (splitData_df.columns))\n",
    "splitData_listo = []\n",
    "\n",
    "for i in tqdm(range(0, 13087)):\n",
    "    if splitData_df[splitData_df['case_id'] == i].iloc[0]['time:timestamp'] > splitData_limit_date:\n",
    "        splitData_listo.append(i)\n",
    "\n",
    "for i in tqdm(range(0, len(splitData_listo))):\n",
    "    splitData_df_test = splitData_df_test.append(splitData_df[splitData_df['case_id'] == splitData_listo[i]])\n",
    "\n",
    "splitData_df_test = splitData_df_test.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Baseline\n",
    "\n",
    "def load_dataset_csv(file_name : str, file_attribute_name : str) -> list:\n",
    "    #Loading the two datasets. So far we'll only be using the BPI.csv one\n",
    "    #This also parses the date column\n",
    "    df = pd.read_csv(file_name)\n",
    "    df['time:timestamp'] = df['time:timestamp'].apply(fix_time)\n",
    "    df_attr = pd.read_csv(file_attribute_name)\n",
    "    return df, df_attr\n",
    "\n",
    "# The current version of the tool works with the 2012 dataset!!!\n",
    "baseline_df, baseline_df_attr = load_dataset_csv('Datasets/BPI_2012.csv', 'Datasets/BPI_attr_2012.csv')\n",
    "\n",
    "#Let us change the column names to the aforementioned\n",
    "baseline_df.columns = ['case_id', 'step_number', 'org:resource', 'lifecycle:transition',\n",
    "       'concept:name', 'time:timestamp']\n",
    "\n",
    "#Erasing all the non-complete actions from the database:\n",
    "baseline_df = baseline_df[baseline_df['lifecycle:transition'] == 'COMPLETE']\n",
    "\n",
    "baseline_df = baseline_df.reset_index()\n",
    "\n",
    "#I used to suppress the output of the cell, but didn't know it also does not save any progress within this cell\n",
    "#So in order for df to update globally, we can't suppress the output unfortunately\n",
    "baseline_df.drop('index', axis=1)\n",
    "\n",
    "def compute_time_difference():\n",
    "    #Set the time difference column\n",
    "    #This function is places here because of the erased non-complete actions\n",
    "    baseline_df['time:time_between'] = baseline_df['time:timestamp'].diff()\n",
    "    baseline_df.loc[baseline_df['step_number'] == 0, 'time:time_between'] = pd.Timedelta(0)\n",
    "    \n",
    "compute_time_difference()\n",
    "\n",
    "def creating_dict_for_next_step_stats (df : pd.DataFrame, concept_name : str) -> dict:\n",
    "    '''For an input action checks for all the possible next actions and counts their occurence'''\n",
    "    \n",
    "    dic_occurrence = {}\n",
    "    dic_total_time = {}\n",
    "    ids = list(df['case_id']) + ['editor: last id'] #Otherwise we check i+1-th position that does not exist\n",
    "    times = list(df['time:time_between']) + [pd.Timedelta(0)] #Otherwise we check i+1-th position that does not exist\n",
    "    names = df['concept:name']\n",
    "    df_concept = df[names == concept_name]\n",
    "    \n",
    "    for i, row in df_concept.iterrows():\n",
    "        \n",
    "        if (ids[i] == ids[i+1]): #an instance of the same case\n",
    "            \n",
    "            if (names[i+1] not in dic_occurrence):\n",
    "                dic_occurrence[names[i+1]] = 1\n",
    "                dic_total_time[names[i+1]] = times[i+1]\n",
    "            else:\n",
    "                dic_occurrence[names[i+1]] += 1\n",
    "                dic_total_time[names[i+1]] += times[i+1]\n",
    "                \n",
    "        else: #the last instance of the case\n",
    "            \n",
    "            if ('editor: close_case' not in dic_occurrence):\n",
    "                dic_occurrence['editor: close_case'] = 1\n",
    "                dic_total_time['editor: close_case'] = times[i+1]\n",
    "            else:\n",
    "                dic_occurrence['editor: close_case'] += 1\n",
    "                dic_total_time['editor: close_case'] += times[i+1]\n",
    "    \n",
    "    #Compute average time\n",
    "    dic_avg_time = {}\n",
    "    \n",
    "    for key in dic_total_time:\n",
    "        dic_avg_time[key] = dic_total_time[key] / dic_occurrence[key]\n",
    "        \n",
    "    return(dic_occurrence, dic_avg_time)\n",
    "\n",
    "creating_dict_for_next_step_stats(baseline_df, 'A_SUBMITTED')\n",
    "\n",
    "def choosing_next_action(dic : dict):\n",
    "    '''Finds the max value of the input dict and returns the key of the max value'''\n",
    "    \n",
    "    max_key = max(dic, key=dic.get)\n",
    "    \n",
    "    return(max_key)\n",
    "\n",
    "choosing_next_action({'A_PARTLYSUBMITTED': 910, \"wow\": 21, \"not_wow\": 37})\n",
    "\n",
    "def cycles_shortcut(actions : list, concept_name : str, max_length : int) -> list or bool:\n",
    "    '''For saving the operating time, we will try to terminate the baseline early if we get into a loop\n",
    "    max_length is the longest_trace parameter'''\n",
    "    \n",
    "    if(concept_name in actions): #the action has already been done\n",
    "        \n",
    "        if(actions[-1] == concept_name): #and it's the most recent action (self-loop)\n",
    "            \n",
    "            while(len(actions) < max_length): #filling the rest of the list with the current action if we're in a self-loop\n",
    "                actions.append(concept_name)\n",
    "        \n",
    "        else: #it is not the most recent action\n",
    "            placement = actions.index(concept_name) #locating the index of the \"duplicate\"\n",
    "            aid_array = actions[placement:] #copying the values\n",
    "            print(\"aid_array = \", aid_array)\n",
    "            \n",
    "            actions = actions + [0] * (max_length-len(actions)) #making [x, y, z, x] into [x, y, z, x, 0, 0, 0, ...]\n",
    "            print(\"actions = \", actions)\n",
    "            \n",
    "            for i in range(placement+1, max_length): #iterating only over all the indices of 0's in actions\n",
    "                actions[i] = aid_array[(i-placement)%len(aid_array)] #copying the list's values over and over again\n",
    "        \n",
    "        return(actions) #This return has to be then the return of the iterated_expected_actions\n",
    "    \n",
    "    else:\n",
    "        return(False)\n",
    "    \n",
    "cycles_shortcut([2, 1, 3, 7], 3, 15)\n",
    "\n",
    "def iterating_expected_actions(df : pd.DataFrame, concept_name : str, n : int) -> list:\n",
    "    '''concept_name is the starting point (first action)\n",
    "    n is the length of the longest trace ever observed\n",
    "    It is stored in lonest_trace but for runtime reasons, use n so far'''\n",
    "    \n",
    "    longest_trace = max(df['step_number']) #finding the longest trace in the database (nr of steps)\n",
    "    #note that we determine this AFTER deleting some rows with uncomplete steps. We should be running this on full df\n",
    "    \n",
    "    i = 0\n",
    "    actions = [concept_name] #Here is the list that will store all the subsequent actions the algorithm decices to perform\n",
    "    while (i < n): #terminate if we are exceeding the max number of steps\n",
    "        wow = creating_dict_for_next_step_stats(df, concept_name)[0] #list all possible options\n",
    "        concept_name = choosing_next_action(wow) #Choose the most commonly used option\n",
    "        \n",
    "        if(cycles_shortcut(actions, concept_name, n) != False): #Checks if we are stuck in a loop\n",
    "            print(\"we are stuck in a loop\")\n",
    "            return(cycles_shortcut(actions, concept_name, n))\n",
    "        \n",
    "        if(concept_name == 'editor: close_case'): #If it is the \"terminate\" option - terminate\n",
    "            break\n",
    "        actions.append(concept_name) #Add the action to the list\n",
    "        i += 1\n",
    "    \n",
    "    actions.append('editor: close_case')\n",
    "    print('i = ', i, \"n = \", n)\n",
    "    \n",
    "    return(actions)\n",
    "\n",
    "def add_expected_events(df : pd.DataFrame) -> list:\n",
    "    all_events = df['concept:name'].unique()\n",
    "    next_event_name_dic = {'editor: close_case': 'editor: close_case'}\n",
    "    next_event_duration_dic = {'editor: close_case': pd.Timedelta(0)}\n",
    "    \n",
    "    for event in all_events:\n",
    "        next_step_stats = creating_dict_for_next_step_stats(df, event)\n",
    "        wow = next_step_stats[0] #list all possible options\n",
    "        concept_name = choosing_next_action(wow) #Choose the most commonly used option\n",
    "        next_event_name_dic[event] = concept_name\n",
    "        next_event_duration_dic[event] = next_step_stats[1][concept_name]\n",
    "    \n",
    "    return next_event_name_dic, next_event_duration_dic\n",
    "\n",
    "#Get list of all expected next events and the expected time till that next event\n",
    "baseline_all_expected_events = add_expected_events(baseline_df)\n",
    "baseline_all_expected_events\n",
    "\n",
    "#Add column to dataframe with expected next events and times\n",
    "baseline_df['expect:next_event'] = baseline_df['concept:name'].map(baseline_all_expected_events[0])\n",
    "baseline_df['expect:next_time'] = baseline_df['concept:name'].map(baseline_all_expected_events[1]) + baseline_df['time:timestamp']\n",
    "\n",
    "baseline_df.to_csv('BPI_with_predictions.csv')\n",
    "\n",
    "iterating_expected_actions(baseline_df, 'A_SUBMITTED', 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Baseline Performance Testing\n",
    "\n",
    "baseline_limits = [50, 100, 200, 500, 1000, 2000, 5000, 10000, 20000, 50000, 100000]\n",
    "baseline_runtimes = [0] * len(baseline_limits)\n",
    "\n",
    "for i in range(0, len(baseline_limits)):\n",
    "    print(i)\n",
    "    df_small = baseline_df[:baseline_limits[i]]\n",
    "    time_start = time.time()\n",
    "    iterating_expected_actions(df_small, 'A_SUBMITTED', 15)\n",
    "    time_end = time.time()\n",
    "    baseline_runtimes[i] = time_end-time_start\n",
    "\n",
    "baseline_runtimes\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "baseline_wow = plt.figure(figsize=(7.5, 5))\n",
    "plt.scatter(x = baseline_limits, y=baseline_runtimes, color = '#AB3334')\n",
    "plt.title('Runtime of the baseline algorithm (log scale)', fontsize = 16)\n",
    "plt.ylabel('Operating time [log(s)]', fontsize = 13)\n",
    "plt.xlabel('Input size [log(n)]', fontsize = 13)\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale('log')\n",
    "\n",
    "baseline_wow2 = plt.figure(figsize=(7.5, 5))\n",
    "plt.scatter(x = baseline_limits, y=baseline_runtimes, color = '#420CDA')\n",
    "plt.title('Runtime of the baseline algorithm', fontsize = 16)\n",
    "plt.ylabel('Operating time [s]', fontsize = 13)\n",
    "plt.xlabel('Input size [n]', fontsize = 13)\n",
    "\n",
    "baseline_f, (ax1, ax2) = plt.subplots(1, 2, figsize=(18,6))\n",
    "\n",
    "ax1.scatter(x = baseline_limits, y=baseline_runtimes, color = '#420CDA')\n",
    "ax1.set_title('Runtime of the baseline algorithm', fontsize = 16)\n",
    "ax1.set_xlabel('Input size [n]', fontsize = 13)\n",
    "ax1.set_ylabel('Operating time [s]', fontsize = 13)\n",
    "\n",
    "ax2.scatter(x = baseline_limits, y=baseline_runtimes, color = '#AB3334')\n",
    "ax2.set_title('Runtime of the baseline algorithm (log scale)', fontsize = 16)\n",
    "ax2.set_ylabel('Operating time [log(s)]', fontsize = 13)\n",
    "ax2.set_xlabel('Input size [log(n)]', fontsize = 13)\n",
    "ax2.set_xscale(\"log\")\n",
    "ax2.set_yscale('log')\n",
    "\n",
    "baseline_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing the Baseline\n",
    "\n",
    "testingBaseline_df = df\n",
    "testingBaseline_df = testingBaseline_df.rename(columns={'Unnamed: 0': 'case_id', 'Unnamed: 1': 'step_number'})\n",
    "testingBaseline_df['time:timestamp'] = testingBaseline_df['time:timestamp'].apply(fix_time)\n",
    "    \n",
    "testingBaseline_df_attr = df_attr\n",
    "testingBaseline_df_attr = testingBaseline_df_attr.rename(columns={'Unnamed: 0': 'case_id'})\n",
    "testingBaseline_df_attr['REG_DATE'] = testingBaseline_df_attr['REG_DATE'].apply(fix_time)\n",
    "\n",
    "testingBaseline_df = testingBaseline_df[testingBaseline_df['lifecycle:transition'] == 'COMPLETE']\n",
    "testingBaseline_df = testingBaseline_df.reset_index(drop = True)\n",
    "\n",
    "testingBaseline_df['time:time_between'] = testingBaseline_df['time:timestamp'].diff()\n",
    "testingBaseline_df.loc[testingBaseline_df['step_number'] == 0, 'time:time_between'] = pd.Timedelta(0)\n",
    "\n",
    "#amount of total data that is training data:\n",
    "testingBaseline_train_data = 0.8\n",
    "#amount of train data that is validation data:\n",
    "testingBaseline_validation_data = 0.1\n",
    "\n",
    "testingBaseline_limit_date = testingBaseline_df[testingBaseline_df['case_id'] == round(testingBaseline_df.iloc[-1, 0]*testingBaseline_train_data)].iloc[0]['time:timestamp']\n",
    "#limit_date = datetime.datetime(2012, 2, 3, 1, 1, 1, 633000, tzinfo=datetime.timezone(datetime.timedelta(seconds=7200))) \n",
    "\n",
    "#training data_set\n",
    "testingBaseline_df_train = testingBaseline_df\n",
    "testingBaseline_listo = []\n",
    "\n",
    "for i in tqdm(range(0, 13087)):\n",
    "    if testingBaseline_df[testingBaseline_df['case_id'] == i].iloc[-1]['time:timestamp'] > testingBaseline_limit_date:\n",
    "        testingBaseline_listo.append(i)\n",
    "\n",
    "for i in tqdm(range(0, len(testingBaseline_listo))):\n",
    "    testingBaseline_df_train = testingBaseline_df_train.drop(testingBaseline_df_train[testingBaseline_df_train['case_id']==testingBaseline_listo[i]].index)\n",
    "\n",
    "testingBaseline_df_train = testingBaseline_df_train.reset_index(drop = True)\n",
    "\n",
    "#testing data_set\n",
    "testingBaseline_mask = np.random.rand(len(testingBaseline_df_train)) < testingBaseline_validation_data\n",
    "testingBaseline_df_validation = testingBaseline_df_train[testingBaseline_mask]\n",
    "testingBaseline_df_train = testingBaseline_df_train[~testingBaseline_mask]\n",
    "\n",
    "#testing data_set\n",
    "testingBaseline_df_test = pd.DataFrame(columns = (testingBaseline_df.columns))\n",
    "testingBaseline_listo = []\n",
    "\n",
    "for i in tqdm(range(0, 13087)):\n",
    "    if testingBaseline_df[testingBaseline_df['case_id'] == i].iloc[0]['time:timestamp'] > testingBaseline_limit_date:\n",
    "        testingBaseline_listo.append(i)\n",
    "\n",
    "for i in tqdm(range(0, len(testingBaseline_listo))):\n",
    "    testingBaseline_df_test = testingBaseline_df_test.append(testingBaseline_df[testingBaseline_df['case_id'] == testingBaseline_listo[i]])\n",
    "\n",
    "testingBaseline_df_test = testingBaseline_df_test.reset_index(drop = True)\n",
    "\n",
    "testingBaseline_df_train.to_csv('BPI_2012_train', index=False)\n",
    "\n",
    "testingBaseline_df_validation.to_csv('BPI_2012_validation')\n",
    "\n",
    "testingBaseline_df_test.to_csv('BPI_2012_test', index=False)\n",
    "\n",
    "testingBaseline_df_train = pd.read_csv('BPI_2012_train')\n",
    "testingBaseline_df_train['time:timestamp'] = testingBaseline_df_train['time:timestamp'].apply(fix_time)\n",
    "testingBaseline_df_train['time:time_between'] = testingBaseline_df_train['time:timestamp'].diff()\n",
    "testingBaseline_df_train.loc[testingBaseline_df['step_number'] == 0, 'time:time_between'] = pd.Timedelta(0)\n",
    "\n",
    "testingBaseline_df_test = pd.read_csv('BPI_2012_test')\n",
    "testingBaseline_df_test['time:timestamp'] = testingBaseline_df_test['time:timestamp'].apply(fix_time)\n",
    "testingBaseline_df_test['time:time_between'] = testingBaseline_df_test['time:timestamp'].diff()\n",
    "testingBaseline_df_test.loc[testingBaseline_df['step_number'] == 0, 'time:time_between'] = pd.Timedelta(0)\n",
    "\n",
    "def prediction(prev):\n",
    "    return baseline_all_expected_events[0][prev]\n",
    "\n",
    "testingBaseline_df_test['predicted'] = testingBaseline_df_test['concept:name'].apply(prediction)\n",
    "\n",
    "testingBaseline_df_test['correct'] = np.nan\n",
    "\n",
    "for i in tqdm(range(0, len(testingBaseline_df_test)-1)):\n",
    "    \n",
    "    if testingBaseline_df_test.loc[i, 'case_id'] == testingBaseline_df_test.loc[i+1, 'case_id']:\n",
    "        testingBaseline_df_test.loc[i, 'correct'] = (testingBaseline_df_test.loc[i, 'predicted'] == testingBaseline_df_test.loc[i+1, 'concept:name'])\n",
    "    \n",
    "    else:\n",
    "         testingBaseline_df_test.loc[i, 'correct'] = (testingBaseline_df_test.loc[i, 'predicted'] == 'editor:close_case')\n",
    "            \n",
    "list(testingBaseline_df_test['correct']).count(True)/len(list(testingBaseline_df_test['correct']))\n",
    "\n",
    "def prediction(prev):\n",
    "    return baseline_all_expected_events[1][prev]\n",
    "\n",
    "testingBaseline_df_test['time:between_predicted'] = testingBaseline_df_test['concept:name'].apply(prediction)\n",
    "\n",
    "def time_difference(var):\n",
    "    return abs((var[0] - var[1]).total_seconds())\n",
    "\n",
    "testingBaseline_df_test['time:predicton_off'] = testingBaseline_df_test[['time:time_between', 'time:between_predicted']].apply(time_difference, axis=1)\n",
    "\n",
    "seconds = testingBaseline_df_test['time:predicton_off'].mean()\n",
    "minutes = seconds/60\n",
    "hours = minutes/60\n",
    "days = hours/24\n",
    "print(str(seconds) + ', ' + str(minutes) + ', ' + str(hours) + ', ' + str(days))\n",
    "\n",
    "seconds = testingBaseline_df_test['time:predicton_off'].median()\n",
    "minutes = seconds/60\n",
    "hours = minutes/60\n",
    "days = hours/24\n",
    "print(str(seconds) + ', ' + str(minutes) + ', ' + str(hours) + ', ' + str(days))\n",
    "\n",
    "145472/60/24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_id</th>\n",
       "      <th>A_SUBMITTED</th>\n",
       "      <th>A_PARTLYSUBMITTED</th>\n",
       "      <th>A_PREACCEPTED</th>\n",
       "      <th>W_Completeren aanvraag</th>\n",
       "      <th>A_ACCEPTED</th>\n",
       "      <th>O_SELECTED</th>\n",
       "      <th>A_FINALIZED</th>\n",
       "      <th>O_CREATED</th>\n",
       "      <th>O_SENT</th>\n",
       "      <th>...</th>\n",
       "      <th>O_ACCEPTED</th>\n",
       "      <th>A_ACTIVATED</th>\n",
       "      <th>O_CANCELLED</th>\n",
       "      <th>W_Wijzigen contractgegevens</th>\n",
       "      <th>A_DECLINED</th>\n",
       "      <th>A_CANCELLED</th>\n",
       "      <th>W_Afhandelen leads</th>\n",
       "      <th>O_DECLINED</th>\n",
       "      <th>W_Nabellen incomplete dossiers</th>\n",
       "      <th>W_Beoordelen fraude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   case_id  A_SUBMITTED  A_PARTLYSUBMITTED  A_PREACCEPTED  \\\n",
       "0        0            1                  0              0   \n",
       "1        0            0                  1              0   \n",
       "2        0            0                  0              1   \n",
       "3        0            0                  0              0   \n",
       "4        0            0                  0              0   \n",
       "\n",
       "   W_Completeren aanvraag  A_ACCEPTED  O_SELECTED  A_FINALIZED  O_CREATED  \\\n",
       "0                       0           0           0            0          0   \n",
       "1                       0           0           0            0          0   \n",
       "2                       0           0           0            0          0   \n",
       "3                       1           0           0            0          0   \n",
       "4                       1           0           0            0          0   \n",
       "\n",
       "   O_SENT  ...  O_ACCEPTED  A_ACTIVATED  O_CANCELLED  \\\n",
       "0       0  ...           0            0            0   \n",
       "1       0  ...           0            0            0   \n",
       "2       0  ...           0            0            0   \n",
       "3       0  ...           0            0            0   \n",
       "4       0  ...           0            0            0   \n",
       "\n",
       "   W_Wijzigen contractgegevens  A_DECLINED  A_CANCELLED  W_Afhandelen leads  \\\n",
       "0                            0           0            0                   0   \n",
       "1                            0           0            0                   0   \n",
       "2                            0           0            0                   0   \n",
       "3                            0           0            0                   0   \n",
       "4                            0           0            0                   0   \n",
       "\n",
       "   O_DECLINED  W_Nabellen incomplete dossiers  W_Beoordelen fraude  \n",
       "0           0                               0                    0  \n",
       "1           0                               0                    0  \n",
       "2           0                               0                    0  \n",
       "3           0                               0                    0  \n",
       "4           0                               0                    0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prepare_column_for_clustering(case_id_column, cluster_column):\n",
    "    cluster_column = cluster_column.fillna(-1)\n",
    "    unique_values = cluster_column.unique()\n",
    "    grouped_df = pd.DataFrame({'case_id': case_id_column, 'column': cluster_column})\n",
    "    \n",
    "    for val in unique_values:\n",
    "        grouped_df[val] = 0\n",
    "        grouped_df.loc[grouped_df['column'] == val, val] = 1\n",
    "    \n",
    "    return grouped_df[['case_id'] + list(unique_values)]\n",
    "\n",
    "prepared_column_data = prepare_column_for_clustering(df['case_id'], df['concept:name'])\n",
    "prepared_column_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          5\n",
       "1          5\n",
       "2          5\n",
       "3          5\n",
       "4          5\n",
       "          ..\n",
       "262195    14\n",
       "262196    14\n",
       "262197    14\n",
       "262198    14\n",
       "262199    14\n",
       "Name: concept:name cluster, Length: 262200, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_clusters(prepared_rows):\n",
    "    kmeans = KMeans(n_clusters=15)\n",
    "    \n",
    "    unique_columns = list(prepared_rows.columns)\n",
    "    unique_columns.pop(0)\n",
    "\n",
    "    df_grouped = prepared_rows.groupby('case_id')[unique_columns].sum()\n",
    "    kmeans.fit(df_grouped[unique_columns])\n",
    "    prediction = kmeans.labels_\n",
    "    \n",
    "    return prepared_rows.case_id.map(dict(enumerate(prediction))), kmeans\n",
    "\n",
    "df['concept:name cluster'], cluster_model = get_clusters(prepared_column_data)\n",
    "df['concept:name cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=10)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_tree(df_train, cluster_one, cluster_one_value):\n",
    "    df_train[\"next_event\"] = df_train[\"concept:name\"]\n",
    "    df_train.loc[df['step_number'] == 0, 'next_event'] = 'editor: close_case'\n",
    "    df_train[\"next_event\"] = df_train[\"next_event\"].shift(-1)\n",
    "    df_train.loc[len(df_train) - 1, 'next_event'] = 'editor: close_case'\n",
    "\n",
    "    model = RandomForestClassifier(n_estimators=100, max_depth=10)\n",
    "    \n",
    "    special_df = df_train[df_train[cluster_one] == cluster_one_value].copy()\n",
    "\n",
    "    mapping, reverse_mapping = {}, {}\n",
    "    all_events = ['editor: close_case'] + list(special_df['concept:name'].unique())\n",
    "\n",
    "    for i in range(len(all_events)):\n",
    "        mapping[all_events[i]] = i\n",
    "        reverse_mapping[i] = all_events[i]\n",
    "    \n",
    "    special_df['next_event int'] = special_df['next_event'].map(mapping)\n",
    "    \n",
    "    X_dtc = special_df[[cluster_one, 'step_number', 'time:weekday', 'time:hour']].copy()\n",
    "    y_dtc = special_df[['next_event int']]\n",
    "\n",
    "    model.fit(X_dtc, y_dtc['next_event int'])\n",
    "    \n",
    "    return model, reverse_mapping\n",
    "\n",
    "tree_model, reverse_mapping = get_tree(df, 'concept:name cluster', 0)\n",
    "tree_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          5\n",
       "1          5\n",
       "2          5\n",
       "3          5\n",
       "4          5\n",
       "          ..\n",
       "262195    14\n",
       "262196    14\n",
       "262197    14\n",
       "262198    14\n",
       "262199    14\n",
       "Name: case_id, Length: 262200, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_clusters(cluster_model, prepared_rows):\n",
    "    unique_columns = list(prepared_rows.columns)\n",
    "    unique_columns.pop(0)\n",
    "    \n",
    "    df_grouped = prepared_rows.groupby('case_id')[unique_columns].sum()\n",
    "    \n",
    "    prediction = cluster_model.predict(df_grouped[unique_columns])\n",
    "    return prepared_rows.case_id.map(dict(enumerate(prediction)))\n",
    "\n",
    "predicted_clusters = predict_clusters(cluster_model, prepared_column_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-77-25ac904b6bea>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test['predicted'] = np.vectorize(reverse_mapping.get)(prediction)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_id</th>\n",
       "      <th>step_number</th>\n",
       "      <th>org:resource</th>\n",
       "      <th>lifecycle:transition</th>\n",
       "      <th>concept:name</th>\n",
       "      <th>time:timestamp</th>\n",
       "      <th>time:weekday</th>\n",
       "      <th>time:hour</th>\n",
       "      <th>A_SUBMITTED</th>\n",
       "      <th>A_PARTLYSUBMITTED</th>\n",
       "      <th>...</th>\n",
       "      <th>W_Wijzigen contractgegevens</th>\n",
       "      <th>A_DECLINED</th>\n",
       "      <th>A_CANCELLED</th>\n",
       "      <th>W_Afhandelen leads</th>\n",
       "      <th>O_DECLINED</th>\n",
       "      <th>W_Nabellen incomplete dossiers</th>\n",
       "      <th>W_Beoordelen fraude</th>\n",
       "      <th>concept:name cluster</th>\n",
       "      <th>next_event</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1421</th>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>A_SUBMITTED</td>\n",
       "      <td>2011-10-02 13:24:15.505000+02:00</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1422</th>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>112.0</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>2011-10-02 13:24:15.703000+02:00</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>W_Afhandelen leads</td>\n",
       "      <td>W_Afhandelen leads</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1423</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>112.0</td>\n",
       "      <td>SCHEDULE</td>\n",
       "      <td>W_Afhandelen leads</td>\n",
       "      <td>2011-10-02 13:24:24.443000+02:00</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>W_Afhandelen leads</td>\n",
       "      <td>W_Afhandelen leads</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1424</th>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>11001.0</td>\n",
       "      <td>START</td>\n",
       "      <td>W_Afhandelen leads</td>\n",
       "      <td>2011-10-03 09:30:14.832000+02:00</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A_PREACCEPTED</td>\n",
       "      <td>A_PREACCEPTED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1425</th>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>11001.0</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>A_PREACCEPTED</td>\n",
       "      <td>2011-10-03 09:31:45.662000+02:00</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>W_Completeren aanvraag</td>\n",
       "      <td>W_Completeren aanvraag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247917</th>\n",
       "      <td>12261</td>\n",
       "      <td>64</td>\n",
       "      <td>10609.0</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>O_ACCEPTED</td>\n",
       "      <td>2012-03-12 10:49:14.926000+01:00</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A_APPROVED</td>\n",
       "      <td>W_Nabellen incomplete dossiers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247918</th>\n",
       "      <td>12261</td>\n",
       "      <td>65</td>\n",
       "      <td>10609.0</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>A_APPROVED</td>\n",
       "      <td>2012-03-12 10:49:14.926000+01:00</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A_REGISTERED</td>\n",
       "      <td>W_Nabellen incomplete dossiers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247919</th>\n",
       "      <td>12261</td>\n",
       "      <td>66</td>\n",
       "      <td>10609.0</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>A_REGISTERED</td>\n",
       "      <td>2012-03-12 10:49:14.927000+01:00</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A_ACTIVATED</td>\n",
       "      <td>W_Nabellen incomplete dossiers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247920</th>\n",
       "      <td>12261</td>\n",
       "      <td>67</td>\n",
       "      <td>10609.0</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>A_ACTIVATED</td>\n",
       "      <td>2012-03-12 10:49:14.927000+01:00</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>W_Valideren aanvraag</td>\n",
       "      <td>W_Nabellen incomplete dossiers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247921</th>\n",
       "      <td>12261</td>\n",
       "      <td>68</td>\n",
       "      <td>10609.0</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>W_Valideren aanvraag</td>\n",
       "      <td>2012-03-12 10:49:19.791000+01:00</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>editor: close_case</td>\n",
       "      <td>W_Nabellen incomplete dossiers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14735 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        case_id  step_number  org:resource lifecycle:transition  \\\n",
       "1421         64            0         112.0             COMPLETE   \n",
       "1422         64            1         112.0             COMPLETE   \n",
       "1423         64            2         112.0             SCHEDULE   \n",
       "1424         64            3       11001.0                START   \n",
       "1425         64            4       11001.0             COMPLETE   \n",
       "...         ...          ...           ...                  ...   \n",
       "247917    12261           64       10609.0             COMPLETE   \n",
       "247918    12261           65       10609.0             COMPLETE   \n",
       "247919    12261           66       10609.0             COMPLETE   \n",
       "247920    12261           67       10609.0             COMPLETE   \n",
       "247921    12261           68       10609.0             COMPLETE   \n",
       "\n",
       "                concept:name                    time:timestamp  time:weekday  \\\n",
       "1421             A_SUBMITTED  2011-10-02 13:24:15.505000+02:00             6   \n",
       "1422       A_PARTLYSUBMITTED  2011-10-02 13:24:15.703000+02:00             6   \n",
       "1423      W_Afhandelen leads  2011-10-02 13:24:24.443000+02:00             6   \n",
       "1424      W_Afhandelen leads  2011-10-03 09:30:14.832000+02:00             0   \n",
       "1425           A_PREACCEPTED  2011-10-03 09:31:45.662000+02:00             0   \n",
       "...                      ...                               ...           ...   \n",
       "247917            O_ACCEPTED  2012-03-12 10:49:14.926000+01:00             0   \n",
       "247918            A_APPROVED  2012-03-12 10:49:14.926000+01:00             0   \n",
       "247919          A_REGISTERED  2012-03-12 10:49:14.927000+01:00             0   \n",
       "247920           A_ACTIVATED  2012-03-12 10:49:14.927000+01:00             0   \n",
       "247921  W_Valideren aanvraag  2012-03-12 10:49:19.791000+01:00             0   \n",
       "\n",
       "        time:hour  A_SUBMITTED  A_PARTLYSUBMITTED  ...  \\\n",
       "1421           13            1                  0  ...   \n",
       "1422           13            0                  1  ...   \n",
       "1423           13            0                  0  ...   \n",
       "1424            9            0                  0  ...   \n",
       "1425            9            0                  0  ...   \n",
       "...           ...          ...                ...  ...   \n",
       "247917         10            0                  0  ...   \n",
       "247918         10            0                  0  ...   \n",
       "247919         10            0                  0  ...   \n",
       "247920         10            0                  0  ...   \n",
       "247921         10            0                  0  ...   \n",
       "\n",
       "        W_Wijzigen contractgegevens  A_DECLINED  A_CANCELLED  \\\n",
       "1421                              0           0            0   \n",
       "1422                              0           0            0   \n",
       "1423                              0           0            0   \n",
       "1424                              0           0            0   \n",
       "1425                              0           0            0   \n",
       "...                             ...         ...          ...   \n",
       "247917                            0           0            0   \n",
       "247918                            0           0            0   \n",
       "247919                            0           0            0   \n",
       "247920                            0           0            0   \n",
       "247921                            0           0            0   \n",
       "\n",
       "        W_Afhandelen leads  O_DECLINED  W_Nabellen incomplete dossiers  \\\n",
       "1421                     0           0                               0   \n",
       "1422                     0           0                               0   \n",
       "1423                     1           0                               0   \n",
       "1424                     1           0                               0   \n",
       "1425                     0           0                               0   \n",
       "...                    ...         ...                             ...   \n",
       "247917                   0           0                               0   \n",
       "247918                   0           0                               0   \n",
       "247919                   0           0                               0   \n",
       "247920                   0           0                               0   \n",
       "247921                   0           0                               0   \n",
       "\n",
       "        W_Beoordelen fraude  concept:name cluster              next_event  \\\n",
       "1421                      0                     0       A_PARTLYSUBMITTED   \n",
       "1422                      0                     0      W_Afhandelen leads   \n",
       "1423                      0                     0      W_Afhandelen leads   \n",
       "1424                      0                     0           A_PREACCEPTED   \n",
       "1425                      0                     0  W_Completeren aanvraag   \n",
       "...                     ...                   ...                     ...   \n",
       "247917                    0                     0              A_APPROVED   \n",
       "247918                    0                     0            A_REGISTERED   \n",
       "247919                    0                     0             A_ACTIVATED   \n",
       "247920                    0                     0    W_Valideren aanvraag   \n",
       "247921                    0                     0      editor: close_case   \n",
       "\n",
       "                             predicted  \n",
       "1421                 A_PARTLYSUBMITTED  \n",
       "1422                W_Afhandelen leads  \n",
       "1423                W_Afhandelen leads  \n",
       "1424                     A_PREACCEPTED  \n",
       "1425            W_Completeren aanvraag  \n",
       "...                                ...  \n",
       "247917  W_Nabellen incomplete dossiers  \n",
       "247918  W_Nabellen incomplete dossiers  \n",
       "247919  W_Nabellen incomplete dossiers  \n",
       "247920  W_Nabellen incomplete dossiers  \n",
       "247921  W_Nabellen incomplete dossiers  \n",
       "\n",
       "[14735 rows x 35 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_value(tree, df_test, cluster_one, reverse_mapping):\n",
    "    df_predict = df_test.copy()\n",
    "    X_dtc = df_test[[cluster_one, 'step_number', 'time:weekday', 'time:hour']].copy()\n",
    "    \n",
    "    prediction = tree.predict(X_dtc)\n",
    "    df_test['predicted'] = np.vectorize(reverse_mapping.get)(prediction)\n",
    "    return df_test\n",
    "    \n",
    "predict_value(tree_model, df[df['concept:name cluster'] == 0], 'concept:name cluster', reverse_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
