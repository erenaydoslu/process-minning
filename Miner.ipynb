{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import datetime\n",
    "import random\n",
    "import time\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.tree import DecisionTreeClassifier  # for decision tree mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XES TO CSV\n",
    "xesToCsv_BPI = xes_importer.apply(\"Datasets/BPI_Challenge_2012.xes\")\n",
    "\n",
    "xesToCsv_listo = []\n",
    "xesToCsv_dic = {'no': -1}\n",
    "xesToCsv_prev_attr = 'no'\n",
    "xesToCsv_counter = 0\n",
    "xesToCsv_cur_attr = 'no'\n",
    "\n",
    "for i in range(0, len(xesToCsv_BPI)):\n",
    "\n",
    "    for j in range(0, len(xesToCsv_BPI[i])):\n",
    "        xesToCsv_attr_list = list(xesToCsv_BPI[i][j])\n",
    "    \n",
    "        for k in range(0, len(xesToCsv_attr_list)):\n",
    "            xesToCsv_prev_attr = xesToCsv_cur_attr\n",
    "            xesToCsv_cur_attr = xesToCsv_attr_list[k]\n",
    "\n",
    "            if xesToCsv_cur_attr not in xesToCsv_listo:\n",
    "                xesToCsv_value = xesToCsv_dic[xesToCsv_prev_attr] + 1\n",
    "            \n",
    "                for key in xesToCsv_dic:\n",
    "                    if xesToCsv_dic[key] >= xesToCsv_value:\n",
    "                        xesToCsv_dic[key] += 1\n",
    "            \n",
    "                xesToCsv_dic[xesToCsv_cur_attr] = xesToCsv_value\n",
    "                xesToCsv_listo.insert(xesToCsv_value, xesToCsv_cur_attr)\n",
    "        \n",
    "        xesToCsv_cur_attr = 'no'\n",
    "        \n",
    "        \n",
    "xesToCsv_chain = []\n",
    "xesToCsv_event = []\n",
    "\n",
    "for i in range(0, len(xesToCsv_BPI)):\n",
    "    for j in range(0, len(xesToCsv_BPI[i])):\n",
    "        xesToCsv_chain.append(i)\n",
    "        xesToCsv_event.append(j)\n",
    "        \n",
    "xesToCsv_df_BPI= pd.DataFrame(index=[np.array(xesToCsv_chain), np.array(xesToCsv_event)], columns = xesToCsv_listo)\n",
    "\n",
    "for i in range(0, len(xesToCsv_BPI)):\n",
    "    \n",
    "    for j in range(0, len(xesToCsv_BPI[i])):\n",
    "\n",
    "        xesToCsv_attr = xesToCsv_BPI[i][j]\n",
    "        \n",
    "        for a in xesToCsv_attr:\n",
    "            xesToCsv_df_BPI.loc[(i, j), a] = xesToCsv_attr[a]\n",
    "            \n",
    "            \n",
    "xesToCsv_df_BPI.to_csv('Datasets/BPI.csv')\n",
    "\n",
    "xesToCsv_attr_listo = []\n",
    "xesToCsv_attr_dic = {'no': -1}\n",
    "xesToCsv_prev_attr = 'no'\n",
    "xesToCsv_counter = 0\n",
    "xesToCsv_cur_attr = 'no'\n",
    "\n",
    "for i in range(0, len(xesToCsv_BPI)):\n",
    "    xesToCsv_attr_list = list(xesToCsv_BPI[i].attributes)\n",
    "    \n",
    "    for k in range(0, len(xesToCsv_attr_list)):\n",
    "        xesToCsv_prev_attr = xesToCsv_cur_attr\n",
    "        xesToCsv_cur_attr = xesToCsv_attr_list[k]\n",
    "\n",
    "        if xesToCsv_cur_attr not in xesToCsv_attr_listo:\n",
    "            xesToCsv_value = xesToCsv_attr_dic[xesToCsv_prev_attr] + 1\n",
    "            \n",
    "            for key in xesToCsv_attr_dic:\n",
    "                if xesToCsv_attr_dic[key] >= xesToCsv_value:\n",
    "                    xesToCsv_attr_dic[key] += 1\n",
    "            \n",
    "            xesToCsv_attr_dic[xesToCsv_cur_attr] = xesToCsv_value\n",
    "            xesToCsv_attr_listo.insert(xesToCsv_value, xesToCsv_cur_attr)\n",
    "    \n",
    "    xesToCsv_cur_attr = 'no'\n",
    "    \n",
    "    \n",
    "xesToCsv_attr_chain = []\n",
    "\n",
    "for i in range(0, len(xesToCsv_BPI)):\n",
    "    xesToCsv_attr_chain.append(i)\n",
    "    \n",
    "\n",
    "xesToCsv_df_BPI_attr = pd.DataFrame(index = [np.array(xesToCsv_attr_chain)], columns = xesToCsv_attr_listo)\n",
    "\n",
    "\n",
    "for i in range(0, len(xesToCsv_BPI)):\n",
    "\n",
    "    xesToCsv_attr = xesToCsv_BPI[i].attributes\n",
    "    \n",
    "    for a in xesToCsv_attr:\n",
    "        xesToCsv_df_BPI_attr.loc[i, a] = xesToCsv_attr[a]\n",
    "        \n",
    "xesToCsv_df_BPI_attr.to_csv('Datasets/BPI_attr.csv')\n",
    "\n",
    "if 'Unnamed: 0' in xesToCsv_df_BPI.columns:\n",
    "    xesToCsv_df_BPI = xesToCsv_df_BPI.rename(columns={'Unnamed: 0': 'chain', 'Unnamed: 1': 'event'})\n",
    "    xesToCsv_df_BPI = xesToCsv_df_BPI.set_index(['chain', 'event'])\n",
    "    xesToCsv_df_BPI_attr = xesToCsv_df_BPI_attr.rename(columns={'Unnamed: 0': 'chain'})\n",
    "    xesToCsv_df_BPI_attr = xesToCsv_df_BPI_attr.set_index('chain')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Load\n",
    "\n",
    "def fix_time(time):\n",
    "    return datetime.datetime.fromisoformat(time)\n",
    "\n",
    "def load_data(BPI = 'BPI.csv', BPI_attr = 'BPI_attr.h5',  data2012 = False):\n",
    "    df_BPI = pd.read_csv(BPI)\n",
    "    df_BPI_attr = pd.read_csv(BPI_attr)\n",
    "    \n",
    "    if 'Unnamed: 0' in df_BPI.columns:\n",
    "        df_BPI = df_BPI.rename(columns={'Unnamed: 0': 'chain', 'Unnamed: 1': 'event'})\n",
    "        df_BPI = df_BPI.set_index(['chain', 'event'])\n",
    "        df_BPI_attr = df_BPI_attr.rename(columns={'Unnamed: 0': 'chain'})\n",
    "        df_BPI_attr = df_BPI_attr.set_index('chain')\n",
    "    \n",
    "    df_BPI['time:timestamp'] = df_BPI['time:timestamp'].apply(fix_time)\n",
    "\n",
    "    if data2012:\n",
    "        df_BPI_attr['REG_DATE'] = df_BPI_attr['REG_DATE'].apply(fix_time)\n",
    "    \n",
    "    df_BPI['time:weekday'] = [x.weekday() for x in df_BPI['time:timestamp']]\n",
    "    df_BPI['time:hour'] = [x.hour for x in df_BPI['time:timestamp']]\n",
    "    return df_BPI, df_BPI_attr\n",
    "\n",
    "def load_data_xes(data):\n",
    "    BPI = xes_importer.apply(data)\n",
    "    \n",
    "df, df_attr = load_data(BPI = 'Datasets/BPI_2012.csv', BPI_attr = 'Datasets/BPI_attr_2012.csv', data2012 = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split Data\n",
    "\n",
    "splitData_df = df\n",
    "splitData_df = splitData_df.rename(columns={'Unnamed: 0': 'case_id', 'Unnamed: 1': 'step_number'})\n",
    "splitData_df['time:timestamp'] = splitData_df['time:timestamp'].apply(fix_time)\n",
    "    \n",
    "splitData_df_attr = df_attr\n",
    "splitData_df_attr = splitData_df_attr.rename(columns={'Unnamed: 0': 'case_id'})\n",
    "splitData_df_attr['REG_DATE'] = splitData_df_attr['REG_DATE'].apply(fix_time)\n",
    "\n",
    "splitData_limit_date = datetime.datetime(2012, 2, 3, 1, 1, 1, 633000, tzinfo=datetime.timezone(datetime.timedelta(seconds=7200)))\n",
    "\n",
    "#training data_set\n",
    "splitData_df_train = splitData_df\n",
    "#df_train = pd.DataFrame(columns = (df.columns))\n",
    "\n",
    "splitData_listo = []\n",
    "\n",
    "for i in tqdm(range(0, 13087)):\n",
    "    if splitData_df[splitData_df['case_id'] == i].iloc[-1]['time:timestamp'] > splitData_limit_date:\n",
    "        splitData_listo.append(i)\n",
    "\n",
    "for i in tqdm(range(0, len(splitData_listo))):\n",
    "    splitData_df_train = splitData_df_train.drop(splitData_df_train[splitData_df_train['case_id'] == splitData_listo[i]].index)\n",
    "\n",
    "#for i in tqdm(range(0, len(listo))):\n",
    "    #df_train = df_train.append(df[df['case_id'] == listo[i]])\n",
    "\n",
    "splitData_df_train = splitData_df_train.reset_index(drop = True)\n",
    "\n",
    "#testing data_set\n",
    "splitData_df_test = pd.DataFrame(columns = (splitData_df.columns))\n",
    "splitData_listo = []\n",
    "\n",
    "for i in tqdm(range(0, 13087)):\n",
    "    if splitData_df[splitData_df['case_id'] == i].iloc[0]['time:timestamp'] > splitData_limit_date:\n",
    "        splitData_listo.append(i)\n",
    "\n",
    "for i in tqdm(range(0, len(splitData_listo))):\n",
    "    splitData_df_test = splitData_df_test.append(splitData_df[splitData_df['case_id'] == splitData_listo[i]])\n",
    "\n",
    "splitData_df_test = splitData_df_test.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aid_array =  [3, 7]\n",
      "actions =  [2, 1, 3, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\datetimelike.py:1108: PerformanceWarning: Adding/subtracting object-dtype array to TimedeltaArray not vectorized\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we are stuck in a loop\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['A_SUBMITTED',\n",
       " 'A_PARTLYSUBMITTED',\n",
       " 'A_PREACCEPTED',\n",
       " 'W_Completeren aanvraag',\n",
       " 'W_Completeren aanvraag',\n",
       " 'W_Completeren aanvraag',\n",
       " 'W_Completeren aanvraag',\n",
       " 'W_Completeren aanvraag',\n",
       " 'W_Completeren aanvraag',\n",
       " 'W_Completeren aanvraag',\n",
       " 'W_Completeren aanvraag',\n",
       " 'W_Completeren aanvraag',\n",
       " 'W_Completeren aanvraag',\n",
       " 'W_Completeren aanvraag',\n",
       " 'W_Completeren aanvraag']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Baseline\n",
    "\n",
    "def load_dataset_csv(file_name : str, file_attribute_name : str) -> list:\n",
    "    #Loading the two datasets. So far we'll only be using the BPI.csv one\n",
    "    #This also parses the date column\n",
    "    df = pd.read_csv(file_name)\n",
    "    df['time:timestamp'] = df['time:timestamp'].apply(fix_time)\n",
    "    df_attr = pd.read_csv(file_attribute_name)\n",
    "    return df, df_attr\n",
    "\n",
    "# The current version of the tool works with the 2012 dataset!!!\n",
    "baseline_df, baseline_df_attr = load_dataset_csv('Datasets/BPI_2012.csv', 'Datasets/BPI_attr_2012.csv')\n",
    "\n",
    "#Let us change the column names to the aforementioned\n",
    "baseline_df.columns = ['case_id', 'step_number', 'org:resource', 'lifecycle:transition',\n",
    "       'concept:name', 'time:timestamp']\n",
    "\n",
    "#Erasing all the non-complete actions from the database:\n",
    "baseline_df = baseline_df[baseline_df['lifecycle:transition'] == 'COMPLETE']\n",
    "\n",
    "baseline_df = baseline_df.reset_index()\n",
    "\n",
    "#I used to suppress the output of the cell, but didn't know it also does not save any progress within this cell\n",
    "#So in order for df to update globally, we can't suppress the output unfortunately\n",
    "baseline_df.drop('index', axis=1)\n",
    "\n",
    "def compute_time_difference():\n",
    "    #Set the time difference column\n",
    "    #This function is places here because of the erased non-complete actions\n",
    "    baseline_df['time:time_between'] = baseline_df['time:timestamp'].diff()\n",
    "    baseline_df.loc[baseline_df['step_number'] == 0, 'time:time_between'] = pd.Timedelta(0)\n",
    "    \n",
    "compute_time_difference()\n",
    "\n",
    "def parse_timestamp_data():\n",
    "    # Adds extra time related columns to the dataset to be used later\n",
    "    # 0:Monday,..., 6:Sunday\n",
    "    baseline_df['time:weekday'] = [x.weekday() for x in baseline_df['time:timestamp']]\n",
    "    baseline_df['time:hour'] = [x.hour for x in baseline_df['time:timestamp']]\n",
    "    \n",
    "parse_timestamp_data()\n",
    "\n",
    "def creating_dict_for_next_step_stats (df : pd.DataFrame, concept_name : str) -> dict:\n",
    "    '''For an input action checks for all the possible next actions and counts their occurence'''\n",
    "    \n",
    "    dic_occurrence = {}\n",
    "    dic_total_time = {}\n",
    "    ids = list(df['case_id']) + ['editor: last id'] #Otherwise we check i+1-th position that does not exist\n",
    "    times = list(df['time:time_between']) + [pd.Timedelta(0)] #Otherwise we check i+1-th position that does not exist\n",
    "    names = df['concept:name']\n",
    "    df_concept = df[names == concept_name]\n",
    "    \n",
    "    for i, row in df_concept.iterrows():\n",
    "        \n",
    "        if (ids[i] == ids[i+1]): #an instance of the same case\n",
    "            \n",
    "            if (names[i+1] not in dic_occurrence):\n",
    "                dic_occurrence[names[i+1]] = 1\n",
    "                dic_total_time[names[i+1]] = times[i+1]\n",
    "            else:\n",
    "                dic_occurrence[names[i+1]] += 1\n",
    "                dic_total_time[names[i+1]] += times[i+1]\n",
    "                \n",
    "        else: #the last instance of the case\n",
    "            \n",
    "            if ('editor: close_case' not in dic_occurrence):\n",
    "                dic_occurrence['editor: close_case'] = 1\n",
    "                dic_total_time['editor: close_case'] = times[i+1]\n",
    "            else:\n",
    "                dic_occurrence['editor: close_case'] += 1\n",
    "                dic_total_time['editor: close_case'] += times[i+1]\n",
    "    \n",
    "    #Compute average time\n",
    "    dic_avg_time = {}\n",
    "    \n",
    "    for key in dic_total_time:\n",
    "        dic_avg_time[key] = dic_total_time[key] / dic_occurrence[key]\n",
    "        \n",
    "    return(dic_occurrence, dic_avg_time)\n",
    "\n",
    "creating_dict_for_next_step_stats(baseline_df, 'A_SUBMITTED')\n",
    "\n",
    "def choosing_next_action(dic : dict):\n",
    "    '''Finds the max value of the input dict and returns the key of the max value'''\n",
    "    \n",
    "    max_key = max(dic, key=dic.get)\n",
    "    \n",
    "    return(max_key)\n",
    "\n",
    "choosing_next_action({'A_PARTLYSUBMITTED': 910, \"wow\": 21, \"not_wow\": 37})\n",
    "\n",
    "def cycles_shortcut(actions : list, concept_name : str, max_length : int) -> list or bool:\n",
    "    '''For saving the operating time, we will try to terminate the baseline early if we get into a loop\n",
    "    max_length is the longest_trace parameter'''\n",
    "    \n",
    "    if(concept_name in actions): #the action has already been done\n",
    "        \n",
    "        if(actions[-1] == concept_name): #and it's the most recent action (self-loop)\n",
    "            \n",
    "            while(len(actions) < max_length): #filling the rest of the list with the current action if we're in a self-loop\n",
    "                actions.append(concept_name)\n",
    "        \n",
    "        else: #it is not the most recent action\n",
    "            placement = actions.index(concept_name) #locating the index of the \"duplicate\"\n",
    "            aid_array = actions[placement:] #copying the values\n",
    "            print(\"aid_array = \", aid_array)\n",
    "            \n",
    "            actions = actions + [0] * (max_length-len(actions)) #making [x, y, z, x] into [x, y, z, x, 0, 0, 0, ...]\n",
    "            print(\"actions = \", actions)\n",
    "            \n",
    "            for i in range(placement+1, max_length): #iterating only over all the indices of 0's in actions\n",
    "                actions[i] = aid_array[(i-placement)%len(aid_array)] #copying the list's values over and over again\n",
    "        \n",
    "        return(actions) #This return has to be then the return of the iterated_expected_actions\n",
    "    \n",
    "    else:\n",
    "        return(False)\n",
    "    \n",
    "cycles_shortcut([2, 1, 3, 7], 3, 15)\n",
    "\n",
    "def iterating_expected_actions(df : pd.DataFrame, concept_name : str, n : int) -> list:\n",
    "    '''concept_name is the starting point (first action)\n",
    "    n is the length of the longest trace ever observed\n",
    "    It is stored in lonest_trace but for runtime reasons, use n so far'''\n",
    "    \n",
    "    longest_trace = max(df['step_number']) #finding the longest trace in the database (nr of steps)\n",
    "    #note that we determine this AFTER deleting some rows with uncomplete steps. We should be running this on full df\n",
    "    \n",
    "    i = 0\n",
    "    actions = [concept_name] #Here is the list that will store all the subsequent actions the algorithm decices to perform\n",
    "    while (i < n): #terminate if we are exceeding the max number of steps\n",
    "        wow = creating_dict_for_next_step_stats(df, concept_name)[0] #list all possible options\n",
    "        concept_name = choosing_next_action(wow) #Choose the most commonly used option\n",
    "        \n",
    "        if(cycles_shortcut(actions, concept_name, n) != False): #Checks if we are stuck in a loop\n",
    "            print(\"we are stuck in a loop\")\n",
    "            return(cycles_shortcut(actions, concept_name, n))\n",
    "        \n",
    "        if(concept_name == 'editor: close_case'): #If it is the \"terminate\" option - terminate\n",
    "            break\n",
    "        actions.append(concept_name) #Add the action to the list\n",
    "        i += 1\n",
    "    \n",
    "    actions.append('editor: close_case')\n",
    "    print('i = ', i, \"n = \", n)\n",
    "    \n",
    "    return(actions)\n",
    "\n",
    "def add_expected_events(df : pd.DataFrame) -> list:\n",
    "    all_events = df['concept:name'].unique()\n",
    "    next_event_name_dic = {'editor: close_case': 'editor: close_case'}\n",
    "    next_event_duration_dic = {'editor: close_case': pd.Timedelta(0)}\n",
    "    \n",
    "    for event in all_events:\n",
    "        next_step_stats = creating_dict_for_next_step_stats(df, event)\n",
    "        wow = next_step_stats[0] #list all possible options\n",
    "        concept_name = choosing_next_action(wow) #Choose the most commonly used option\n",
    "        next_event_name_dic[event] = concept_name\n",
    "        next_event_duration_dic[event] = next_step_stats[1][concept_name]\n",
    "    \n",
    "    return next_event_name_dic, next_event_duration_dic\n",
    "\n",
    "#Get list of all expected next events and the expected time till that next event\n",
    "baseline_all_expected_events = add_expected_events(baseline_df)\n",
    "baseline_all_expected_events\n",
    "\n",
    "#Add column to dataframe with expected next events and times\n",
    "baseline_df['expect:next_event'] = baseline_df['concept:name'].map(baseline_all_expected_events[0])\n",
    "baseline_df['expect:next_time'] = baseline_df['concept:name'].map(baseline_all_expected_events[1]) + baseline_df['time:timestamp']\n",
    "\n",
    "baseline_df.to_csv('BPI_with_predictions.csv')\n",
    "\n",
    "iterating_expected_actions(baseline_df, 'A_SUBMITTED', 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Baseline Performance Testing\n",
    "\n",
    "baseline_limits = [50, 100, 200, 500, 1000, 2000, 5000, 10000, 20000, 50000, 100000]\n",
    "baseline_runtimes = [0] * len(baseline_limits)\n",
    "\n",
    "for i in range(0, len(baseline_limits)):\n",
    "    print(i)\n",
    "    df_small = baseline_df[:baseline_limits[i]]\n",
    "    time_start = time.time()\n",
    "    iterating_expected_actions(df_small, 'A_SUBMITTED', 15)\n",
    "    time_end = time.time()\n",
    "    baseline_runtimes[i] = time_end-time_start\n",
    "\n",
    "baseline_runtimes\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "baseline_wow = plt.figure(figsize=(7.5, 5))\n",
    "plt.scatter(x = baseline_limits, y=baseline_runtimes, color = '#AB3334')\n",
    "plt.title('Runtime of the baseline algorithm (log scale)', fontsize = 16)\n",
    "plt.ylabel('Operating time [log(s)]', fontsize = 13)\n",
    "plt.xlabel('Input size [log(n)]', fontsize = 13)\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale('log')\n",
    "\n",
    "baseline_wow2 = plt.figure(figsize=(7.5, 5))\n",
    "plt.scatter(x = baseline_limits, y=baseline_runtimes, color = '#420CDA')\n",
    "plt.title('Runtime of the baseline algorithm', fontsize = 16)\n",
    "plt.ylabel('Operating time [s]', fontsize = 13)\n",
    "plt.xlabel('Input size [n]', fontsize = 13)\n",
    "\n",
    "baseline_f, (ax1, ax2) = plt.subplots(1, 2, figsize=(18,6))\n",
    "\n",
    "ax1.scatter(x = baseline_limits, y=baseline_runtimes, color = '#420CDA')\n",
    "ax1.set_title('Runtime of the baseline algorithm', fontsize = 16)\n",
    "ax1.set_xlabel('Input size [n]', fontsize = 13)\n",
    "ax1.set_ylabel('Operating time [s]', fontsize = 13)\n",
    "\n",
    "ax2.scatter(x = baseline_limits, y=baseline_runtimes, color = '#AB3334')\n",
    "ax2.set_title('Runtime of the baseline algorithm (log scale)', fontsize = 16)\n",
    "ax2.set_ylabel('Operating time [log(s)]', fontsize = 13)\n",
    "ax2.set_xlabel('Input size [log(n)]', fontsize = 13)\n",
    "ax2.set_xscale(\"log\")\n",
    "ax2.set_yscale('log')\n",
    "\n",
    "baseline_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing the Baseline\n",
    "\n",
    "testingBaseline_df = df\n",
    "testingBaseline_df = testingBaseline_df.rename(columns={'Unnamed: 0': 'case_id', 'Unnamed: 1': 'step_number'})\n",
    "testingBaseline_df['time:timestamp'] = testingBaseline_df['time:timestamp'].apply(fix_time)\n",
    "    \n",
    "testingBaseline_df_attr = df_attr\n",
    "testingBaseline_df_attr = testingBaseline_df_attr.rename(columns={'Unnamed: 0': 'case_id'})\n",
    "testingBaseline_df_attr['REG_DATE'] = testingBaseline_df_attr['REG_DATE'].apply(fix_time)\n",
    "\n",
    "testingBaseline_df = testingBaseline_df[testingBaseline_df['lifecycle:transition'] == 'COMPLETE']\n",
    "testingBaseline_df = testingBaseline_df.reset_index(drop = True)\n",
    "\n",
    "testingBaseline_df['time:time_between'] = testingBaseline_df['time:timestamp'].diff()\n",
    "testingBaseline_df.loc[testingBaseline_df['step_number'] == 0, 'time:time_between'] = pd.Timedelta(0)\n",
    "\n",
    "#amount of total data that is training data:\n",
    "testingBaseline_train_data = 0.8\n",
    "#amount of train data that is validation data:\n",
    "testingBaseline_validation_data = 0.1\n",
    "\n",
    "testingBaseline_limit_date = testingBaseline_df[testingBaseline_df['case_id'] == round(testingBaseline_df.iloc[-1, 0]*testingBaseline_train_data)].iloc[0]['time:timestamp']\n",
    "#limit_date = datetime.datetime(2012, 2, 3, 1, 1, 1, 633000, tzinfo=datetime.timezone(datetime.timedelta(seconds=7200))) \n",
    "\n",
    "#training data_set\n",
    "testingBaseline_df_train = testingBaseline_df\n",
    "testingBaseline_listo = []\n",
    "\n",
    "for i in tqdm(range(0, 13087)):\n",
    "    if testingBaseline_df[testingBaseline_df['case_id'] == i].iloc[-1]['time:timestamp'] > testingBaseline_limit_date:\n",
    "        testingBaseline_listo.append(i)\n",
    "\n",
    "for i in tqdm(range(0, len(testingBaseline_listo))):\n",
    "    testingBaseline_df_train = testingBaseline_df_train.drop(testingBaseline_df_train[testingBaseline_df_train['case_id']==testingBaseline_listo[i]].index)\n",
    "\n",
    "testingBaseline_df_train = testingBaseline_df_train.reset_index(drop = True)\n",
    "\n",
    "#testing data_set\n",
    "testingBaseline_mask = np.random.rand(len(testingBaseline_df_train)) < testingBaseline_validation_data\n",
    "testingBaseline_df_validation = testingBaseline_df_train[testingBaseline_mask]\n",
    "testingBaseline_df_train = testingBaseline_df_train[~testingBaseline_mask]\n",
    "\n",
    "#testing data_set\n",
    "testingBaseline_df_test = pd.DataFrame(columns = (testingBaseline_df.columns))\n",
    "testingBaseline_listo = []\n",
    "\n",
    "for i in tqdm(range(0, 13087)):\n",
    "    if testingBaseline_df[testingBaseline_df['case_id'] == i].iloc[0]['time:timestamp'] > testingBaseline_limit_date:\n",
    "        testingBaseline_listo.append(i)\n",
    "\n",
    "for i in tqdm(range(0, len(testingBaseline_listo))):\n",
    "    testingBaseline_df_test = testingBaseline_df_test.append(testingBaseline_df[testingBaseline_df['case_id'] == testingBaseline_listo[i]])\n",
    "\n",
    "testingBaseline_df_test = testingBaseline_df_test.reset_index(drop = True)\n",
    "\n",
    "testingBaseline_df_train.to_csv('BPI_2012_train', index=False)\n",
    "\n",
    "testingBaseline_df_validation.to_csv('BPI_2012_validation')\n",
    "\n",
    "testingBaseline_df_test.to_csv('BPI_2012_test', index=False)\n",
    "\n",
    "testingBaseline_df_train = pd.read_csv('BPI_2012_train')\n",
    "testingBaseline_df_train['time:timestamp'] = testingBaseline_df_train['time:timestamp'].apply(fix_time)\n",
    "testingBaseline_df_train['time:time_between'] = testingBaseline_df_train['time:timestamp'].diff()\n",
    "testingBaseline_df_train.loc[testingBaseline_df['step_number'] == 0, 'time:time_between'] = pd.Timedelta(0)\n",
    "\n",
    "testingBaseline_df_test = pd.read_csv('BPI_2012_test')\n",
    "testingBaseline_df_test['time:timestamp'] = testingBaseline_df_test['time:timestamp'].apply(fix_time)\n",
    "testingBaseline_df_test['time:time_between'] = testingBaseline_df_test['time:timestamp'].diff()\n",
    "testingBaseline_df_test.loc[testingBaseline_df['step_number'] == 0, 'time:time_between'] = pd.Timedelta(0)\n",
    "\n",
    "def prediction(prev):\n",
    "    return baseline_all_expected_events[0][prev]\n",
    "\n",
    "testingBaseline_df_test['predicted'] = testingBaseline_df_test['concept:name'].apply(prediction)\n",
    "\n",
    "testingBaseline_df_test['correct'] = np.nan\n",
    "\n",
    "for i in tqdm(range(0, len(testingBaseline_df_test)-1)):\n",
    "    \n",
    "    if testingBaseline_df_test.loc[i, 'case_id'] == testingBaseline_df_test.loc[i+1, 'case_id']:\n",
    "        testingBaseline_df_test.loc[i, 'correct'] = (testingBaseline_df_test.loc[i, 'predicted'] == testingBaseline_df_test.loc[i+1, 'concept:name'])\n",
    "    \n",
    "    else:\n",
    "         testingBaseline_df_test.loc[i, 'correct'] = (testingBaseline_df_test.loc[i, 'predicted'] == 'editor:close_case')\n",
    "            \n",
    "list(testingBaseline_df_test['correct']).count(True)/len(list(testingBaseline_df_test['correct']))\n",
    "\n",
    "def prediction(prev):\n",
    "    return baseline_all_expected_events[1][prev]\n",
    "\n",
    "testingBaseline_df_test['time:between_predicted'] = testingBaseline_df_test['concept:name'].apply(prediction)\n",
    "\n",
    "def time_difference(var):\n",
    "    return abs((var[0] - var[1]).total_seconds())\n",
    "\n",
    "testingBaseline_df_test['time:predicton_off'] = testingBaseline_df_test[['time:time_between', 'time:between_predicted']].apply(time_difference, axis=1)\n",
    "\n",
    "seconds = testingBaseline_df_test['time:predicton_off'].mean()\n",
    "minutes = seconds/60\n",
    "hours = minutes/60\n",
    "days = hours/24\n",
    "print(str(seconds) + ', ' + str(minutes) + ', ' + str(hours) + ', ' + str(days))\n",
    "\n",
    "seconds = testingBaseline_df_test['time:predicton_off'].median()\n",
    "minutes = seconds/60\n",
    "hours = minutes/60\n",
    "days = hours/24\n",
    "print(str(seconds) + ', ' + str(minutes) + ', ' + str(hours) + ', ' + str(days))\n",
    "\n",
    "145472/60/24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_id</th>\n",
       "      <th>step_number</th>\n",
       "      <th>org:resource</th>\n",
       "      <th>lifecycle:transition</th>\n",
       "      <th>concept:name</th>\n",
       "      <th>time:timestamp</th>\n",
       "      <th>time:weekday</th>\n",
       "      <th>time:hour</th>\n",
       "      <th>concept:name cluster</th>\n",
       "      <th>org:resource cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>A_SUBMITTED</td>\n",
       "      <td>2011-10-01 00:38:44.546000+02:00</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112.0</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>2011-10-01 00:38:44.880000+02:00</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>112.0</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>A_PREACCEPTED</td>\n",
       "      <td>2011-10-01 00:39:37.906000+02:00</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>112.0</td>\n",
       "      <td>SCHEDULE</td>\n",
       "      <td>W_Completeren aanvraag</td>\n",
       "      <td>2011-10-01 00:39:38.875000+02:00</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>START</td>\n",
       "      <td>W_Completeren aanvraag</td>\n",
       "      <td>2011-10-01 11:36:46.437000+02:00</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262195</th>\n",
       "      <td>13086</td>\n",
       "      <td>1</td>\n",
       "      <td>112.0</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>2012-02-29 23:51:17.423000+01:00</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262196</th>\n",
       "      <td>13086</td>\n",
       "      <td>2</td>\n",
       "      <td>112.0</td>\n",
       "      <td>SCHEDULE</td>\n",
       "      <td>W_Afhandelen leads</td>\n",
       "      <td>2012-02-29 23:52:01.287000+01:00</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262197</th>\n",
       "      <td>13086</td>\n",
       "      <td>3</td>\n",
       "      <td>11169.0</td>\n",
       "      <td>START</td>\n",
       "      <td>W_Afhandelen leads</td>\n",
       "      <td>2012-03-01 09:26:46.736000+01:00</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262198</th>\n",
       "      <td>13086</td>\n",
       "      <td>4</td>\n",
       "      <td>11169.0</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>A_DECLINED</td>\n",
       "      <td>2012-03-01 09:27:37.118000+01:00</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262199</th>\n",
       "      <td>13086</td>\n",
       "      <td>5</td>\n",
       "      <td>11169.0</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>W_Afhandelen leads</td>\n",
       "      <td>2012-03-01 09:27:41.325000+01:00</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>262200 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        case_id  step_number  org:resource lifecycle:transition  \\\n",
       "0             0            0         112.0             COMPLETE   \n",
       "1             0            1         112.0             COMPLETE   \n",
       "2             0            2         112.0             COMPLETE   \n",
       "3             0            3         112.0             SCHEDULE   \n",
       "4             0            4           NaN                START   \n",
       "...         ...          ...           ...                  ...   \n",
       "262195    13086            1         112.0             COMPLETE   \n",
       "262196    13086            2         112.0             SCHEDULE   \n",
       "262197    13086            3       11169.0                START   \n",
       "262198    13086            4       11169.0             COMPLETE   \n",
       "262199    13086            5       11169.0             COMPLETE   \n",
       "\n",
       "                  concept:name                    time:timestamp  \\\n",
       "0                  A_SUBMITTED  2011-10-01 00:38:44.546000+02:00   \n",
       "1            A_PARTLYSUBMITTED  2011-10-01 00:38:44.880000+02:00   \n",
       "2                A_PREACCEPTED  2011-10-01 00:39:37.906000+02:00   \n",
       "3       W_Completeren aanvraag  2011-10-01 00:39:38.875000+02:00   \n",
       "4       W_Completeren aanvraag  2011-10-01 11:36:46.437000+02:00   \n",
       "...                        ...                               ...   \n",
       "262195       A_PARTLYSUBMITTED  2012-02-29 23:51:17.423000+01:00   \n",
       "262196      W_Afhandelen leads  2012-02-29 23:52:01.287000+01:00   \n",
       "262197      W_Afhandelen leads  2012-03-01 09:26:46.736000+01:00   \n",
       "262198              A_DECLINED  2012-03-01 09:27:37.118000+01:00   \n",
       "262199      W_Afhandelen leads  2012-03-01 09:27:41.325000+01:00   \n",
       "\n",
       "        time:weekday  time:hour  concept:name cluster  org:resource cluster  \n",
       "0                  5          0                     6                     8  \n",
       "1                  5          0                     6                     8  \n",
       "2                  5          0                     6                     8  \n",
       "3                  5          0                     6                     8  \n",
       "4                  5         11                     6                     8  \n",
       "...              ...        ...                   ...                   ...  \n",
       "262195             2         23                    11                     0  \n",
       "262196             2         23                    11                     0  \n",
       "262197             3          9                    11                     0  \n",
       "262198             3          9                    11                     0  \n",
       "262199             3          9                    11                     0  \n",
       "\n",
       "[262200 rows x 10 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_clusters(cluster_df, column_name):\n",
    "    df = cluster_df.copy()\n",
    "    df[column_name] = df[column_name].fillna(-1)\n",
    "    unique_values = df[column_name].unique()\n",
    "    \n",
    "    for val in unique_values:\n",
    "        df[val] = 0\n",
    "        df.loc[df[column_name] == val, val] = 1\n",
    "        \n",
    "    kmeans = KMeans(n_clusters=15)\n",
    "\n",
    "    df_grouped = df.groupby('case_id')[unique_values].sum()\n",
    "    prediction = kmeans.fit_predict(df_grouped[unique_values])\n",
    "    return dict(enumerate(prediction))\n",
    "\n",
    "df['concept:name cluster'] = df.case_id.map(find_clusters(df, 'concept:name'))\n",
    "df['org:resource cluster'] = df.case_id.map(find_clusters(df, 'org:resource'))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_id</th>\n",
       "      <th>step_number</th>\n",
       "      <th>org:resource</th>\n",
       "      <th>lifecycle:transition</th>\n",
       "      <th>concept:name</th>\n",
       "      <th>time:timestamp</th>\n",
       "      <th>time:weekday</th>\n",
       "      <th>time:hour</th>\n",
       "      <th>concept:name cluster</th>\n",
       "      <th>org:resource cluster</th>\n",
       "      <th>next_event</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>A_SUBMITTED</td>\n",
       "      <td>2011-10-01 00:38:44.546000+02:00</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112.0</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>2011-10-01 00:38:44.880000+02:00</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>A_PREACCEPTED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>112.0</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>A_PREACCEPTED</td>\n",
       "      <td>2011-10-01 00:39:37.906000+02:00</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>W_Completeren aanvraag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>112.0</td>\n",
       "      <td>SCHEDULE</td>\n",
       "      <td>W_Completeren aanvraag</td>\n",
       "      <td>2011-10-01 00:39:38.875000+02:00</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>W_Completeren aanvraag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>START</td>\n",
       "      <td>W_Completeren aanvraag</td>\n",
       "      <td>2011-10-01 11:36:46.437000+02:00</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>A_ACCEPTED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   case_id  step_number  org:resource lifecycle:transition  \\\n",
       "0        0            0         112.0             COMPLETE   \n",
       "1        0            1         112.0             COMPLETE   \n",
       "2        0            2         112.0             COMPLETE   \n",
       "3        0            3         112.0             SCHEDULE   \n",
       "4        0            4           NaN                START   \n",
       "\n",
       "             concept:name                    time:timestamp  time:weekday  \\\n",
       "0             A_SUBMITTED  2011-10-01 00:38:44.546000+02:00             5   \n",
       "1       A_PARTLYSUBMITTED  2011-10-01 00:38:44.880000+02:00             5   \n",
       "2           A_PREACCEPTED  2011-10-01 00:39:37.906000+02:00             5   \n",
       "3  W_Completeren aanvraag  2011-10-01 00:39:38.875000+02:00             5   \n",
       "4  W_Completeren aanvraag  2011-10-01 11:36:46.437000+02:00             5   \n",
       "\n",
       "   time:hour  concept:name cluster  org:resource cluster  \\\n",
       "0          0                     6                     8   \n",
       "1          0                     6                     8   \n",
       "2          0                     6                     8   \n",
       "3          0                     6                     8   \n",
       "4         11                     6                     8   \n",
       "\n",
       "               next_event  \n",
       "0       A_PARTLYSUBMITTED  \n",
       "1           A_PREACCEPTED  \n",
       "2  W_Completeren aanvraag  \n",
       "3  W_Completeren aanvraag  \n",
       "4              A_ACCEPTED  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"next_event\"] = df[\"concept:name\"]\n",
    "df.loc[df['step_number'] == 0, 'next_event'] = 'editor:close_case'\n",
    "df[\"next_event\"] = df[\"next_event\"].shift(-1)\n",
    "df.loc[len(df) - 1, 'next_event'] = 'editor:close_case'\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concept:name</th>\n",
       "      <th>org:resource</th>\n",
       "      <th>step_number</th>\n",
       "      <th>time:weekday</th>\n",
       "      <th>time:hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21140</th>\n",
       "      <td>A_SUBMITTED</td>\n",
       "      <td>112.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21141</th>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>112.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21142</th>\n",
       "      <td>W_Afhandelen leads</td>\n",
       "      <td>112.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21143</th>\n",
       "      <td>W_Afhandelen leads</td>\n",
       "      <td>11122.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21144</th>\n",
       "      <td>A_PREACCEPTED</td>\n",
       "      <td>11122.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238454</th>\n",
       "      <td>W_Nabellen offertes</td>\n",
       "      <td>11049.0</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238455</th>\n",
       "      <td>W_Valideren aanvraag</td>\n",
       "      <td>10972.0</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238456</th>\n",
       "      <td>O_DECLINED</td>\n",
       "      <td>10972.0</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238457</th>\n",
       "      <td>A_DECLINED</td>\n",
       "      <td>10972.0</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238458</th>\n",
       "      <td>W_Valideren aanvraag</td>\n",
       "      <td>10972.0</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1096 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                concept:name  org:resource  step_number  time:weekday  \\\n",
       "21140            A_SUBMITTED         112.0            0             3   \n",
       "21141      A_PARTLYSUBMITTED         112.0            1             3   \n",
       "21142     W_Afhandelen leads         112.0            2             3   \n",
       "21143     W_Afhandelen leads       11122.0            3             3   \n",
       "21144          A_PREACCEPTED       11122.0            4             3   \n",
       "...                      ...           ...          ...           ...   \n",
       "238454   W_Nabellen offertes       11049.0           31             1   \n",
       "238455  W_Valideren aanvraag       10972.0           32             3   \n",
       "238456            O_DECLINED       10972.0           33             3   \n",
       "238457            A_DECLINED       10972.0           34             3   \n",
       "238458  W_Valideren aanvraag       10972.0           35             3   \n",
       "\n",
       "        time:hour  \n",
       "21140          14  \n",
       "21141          14  \n",
       "21142          14  \n",
       "21143          14  \n",
       "21144          14  \n",
       "...           ...  \n",
       "238454         14  \n",
       "238455         18  \n",
       "238456         18  \n",
       "238457         18  \n",
       "238458         18  \n",
       "\n",
       "[1096 rows x 5 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier(max_depth=3)\n",
    "special_df = df[df['concept:name cluster'] == 0]\n",
    "special_df = special_df[special_df['org:resource cluster'] == 1]\n",
    "X_dtc = special_df[['concept:name', 'org:resource', 'step_number', 'time:weekday', 'time:hour']].copy()\n",
    "y_dtc = special_df[['next_event']]\n",
    "X_dtc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
