{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import datetime\n",
    "import random\n",
    "import time\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since the data is already converted, I markdowned the cell below. Remember to de-markdown it before submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#XES TO CSV\n",
    "xesToCsv_BPI = xes_importer.apply(\"Datasets/BPI_Challenge_2012.xes\")\n",
    "\n",
    "xesToCsv_listo = []\n",
    "xesToCsv_dic = {'no': -1}\n",
    "xesToCsv_prev_attr = 'no'\n",
    "xesToCsv_counter = 0\n",
    "xesToCsv_cur_attr = 'no'\n",
    "\n",
    "for i in tqdm(range(0, len(xesToCsv_BPI))):\n",
    "\n",
    "    for j in range(0, len(xesToCsv_BPI[i])):\n",
    "        xesToCsv_attr_list = list(xesToCsv_BPI[i][j])\n",
    "    \n",
    "        for k in range(0, len(xesToCsv_attr_list)):\n",
    "            xesToCsv_prev_attr = xesToCsv_cur_attr\n",
    "            xesToCsv_cur_attr = xesToCsv_attr_list[k]\n",
    "\n",
    "            if xesToCsv_cur_attr not in xesToCsv_listo:\n",
    "                xesToCsv_value = xesToCsv_dic[xesToCsv_prev_attr] + 1\n",
    "            \n",
    "                for key in xesToCsv_dic:\n",
    "                    if xesToCsv_dic[key] >= xesToCsv_value:\n",
    "                        xesToCsv_dic[key] += 1\n",
    "            \n",
    "                xesToCsv_dic[xesToCsv_cur_attr] = xesToCsv_value\n",
    "                xesToCsv_listo.insert(xesToCsv_value, xesToCsv_cur_attr)\n",
    "        \n",
    "        xesToCsv_cur_attr = 'no'\n",
    "        \n",
    "        \n",
    "xesToCsv_chain = []\n",
    "xesToCsv_event = []\n",
    "\n",
    "for i in tqdm(range(0, len(xesToCsv_BPI))):\n",
    "    for j in range(0, len(xesToCsv_BPI[i])):\n",
    "        xesToCsv_chain.append(i)\n",
    "        xesToCsv_event.append(j)\n",
    "        \n",
    "xesToCsv_df_BPI= pd.DataFrame(index=[np.array(xesToCsv_chain), np.array(xesToCsv_event)], columns = xesToCsv_listo)\n",
    "\n",
    "for i in tqdm(range(0, len(xesToCsv_BPI))):\n",
    "    \n",
    "    for j in range(0, len(xesToCsv_BPI[i])):\n",
    "\n",
    "        xesToCsv_attr = xesToCsv_BPI[i][j]\n",
    "        \n",
    "        for a in xesToCsv_attr:\n",
    "            xesToCsv_df_BPI.loc[(i, j), a] = xesToCsv_attr[a]\n",
    "            \n",
    "            \n",
    "xesToCsv_df_BPI.to_csv('Datasets/BPI_2012.csv')\n",
    "\n",
    "xesToCsv_attr_listo = []\n",
    "xesToCsv_attr_dic = {'no': -1}\n",
    "xesToCsv_prev_attr = 'no'\n",
    "xesToCsv_counter = 0\n",
    "xesToCsv_cur_attr = 'no'\n",
    "\n",
    "for i in tqdm(range(0, len(xesToCsv_BPI))):\n",
    "    xesToCsv_attr_list = list(xesToCsv_BPI[i].attributes)\n",
    "    \n",
    "    for k in range(0, len(xesToCsv_attr_list)):\n",
    "        xesToCsv_prev_attr = xesToCsv_cur_attr\n",
    "        xesToCsv_cur_attr = xesToCsv_attr_list[k]\n",
    "\n",
    "        if xesToCsv_cur_attr not in xesToCsv_attr_listo:\n",
    "            xesToCsv_value = xesToCsv_attr_dic[xesToCsv_prev_attr] + 1\n",
    "            \n",
    "            for key in xesToCsv_attr_dic:\n",
    "                if xesToCsv_attr_dic[key] >= xesToCsv_value:\n",
    "                    xesToCsv_attr_dic[key] += 1\n",
    "            \n",
    "            xesToCsv_attr_dic[xesToCsv_cur_attr] = xesToCsv_value\n",
    "            xesToCsv_attr_listo.insert(xesToCsv_value, xesToCsv_cur_attr)\n",
    "    \n",
    "    xesToCsv_cur_attr = 'no'\n",
    "    \n",
    "    \n",
    "xesToCsv_attr_chain = []\n",
    "\n",
    "for i in tqdm(range(0, len(xesToCsv_BPI))):\n",
    "    xesToCsv_attr_chain.append(i)\n",
    "    \n",
    "\n",
    "xesToCsv_df_BPI_attr = pd.DataFrame(index = [np.array(xesToCsv_attr_chain)], columns = xesToCsv_attr_listo)\n",
    "\n",
    "\n",
    "for i in tqdm(range(0, len(xesToCsv_BPI))):\n",
    "\n",
    "    xesToCsv_attr = xesToCsv_BPI[i].attributes\n",
    "    \n",
    "    for a in xesToCsv_attr:\n",
    "        xesToCsv_df_BPI_attr.loc[i, a] = xesToCsv_attr[a]\n",
    "        \n",
    "xesToCsv_df_BPI_attr.to_csv('Datasets/BPI_attr_2012.csv')\n",
    "\n",
    "if 'Unnamed: 0' in xesToCsv_df_BPI.columns:\n",
    "    xesToCsv_df_BPI = xesToCsv_df_BPI.rename(columns={'Unnamed: 0': 'case_id', 'Unnamed: 1': 'step_number'})\n",
    "    xesToCsv_df_BPI_attr = xesToCsv_df_BPI_attr.rename(columns={'Unnamed: 0': 'case_id'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_id</th>\n",
       "      <th>step_number</th>\n",
       "      <th>org:resource</th>\n",
       "      <th>lifecycle:transition</th>\n",
       "      <th>concept:name</th>\n",
       "      <th>time:timestamp</th>\n",
       "      <th>time:weekday</th>\n",
       "      <th>time:hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>A_SUBMITTED</td>\n",
       "      <td>2011-10-01 00:38:44.546000+02:00</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112.0</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>2011-10-01 00:38:44.880000+02:00</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>112.0</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>A_PREACCEPTED</td>\n",
       "      <td>2011-10-01 00:39:37.906000+02:00</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>112.0</td>\n",
       "      <td>SCHEDULE</td>\n",
       "      <td>W_Completeren aanvraag</td>\n",
       "      <td>2011-10-01 00:39:38.875000+02:00</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>START</td>\n",
       "      <td>W_Completeren aanvraag</td>\n",
       "      <td>2011-10-01 11:36:46.437000+02:00</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262195</th>\n",
       "      <td>13086</td>\n",
       "      <td>1</td>\n",
       "      <td>112.0</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>2012-02-29 23:51:17.423000+01:00</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262196</th>\n",
       "      <td>13086</td>\n",
       "      <td>2</td>\n",
       "      <td>112.0</td>\n",
       "      <td>SCHEDULE</td>\n",
       "      <td>W_Afhandelen leads</td>\n",
       "      <td>2012-02-29 23:52:01.287000+01:00</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262197</th>\n",
       "      <td>13086</td>\n",
       "      <td>3</td>\n",
       "      <td>11169.0</td>\n",
       "      <td>START</td>\n",
       "      <td>W_Afhandelen leads</td>\n",
       "      <td>2012-03-01 09:26:46.736000+01:00</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262198</th>\n",
       "      <td>13086</td>\n",
       "      <td>4</td>\n",
       "      <td>11169.0</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>A_DECLINED</td>\n",
       "      <td>2012-03-01 09:27:37.118000+01:00</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262199</th>\n",
       "      <td>13086</td>\n",
       "      <td>5</td>\n",
       "      <td>11169.0</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>W_Afhandelen leads</td>\n",
       "      <td>2012-03-01 09:27:41.325000+01:00</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>262200 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        case_id  step_number  org:resource lifecycle:transition  \\\n",
       "0             0            0         112.0             COMPLETE   \n",
       "1             0            1         112.0             COMPLETE   \n",
       "2             0            2         112.0             COMPLETE   \n",
       "3             0            3         112.0             SCHEDULE   \n",
       "4             0            4           NaN                START   \n",
       "...         ...          ...           ...                  ...   \n",
       "262195    13086            1         112.0             COMPLETE   \n",
       "262196    13086            2         112.0             SCHEDULE   \n",
       "262197    13086            3       11169.0                START   \n",
       "262198    13086            4       11169.0             COMPLETE   \n",
       "262199    13086            5       11169.0             COMPLETE   \n",
       "\n",
       "                  concept:name                    time:timestamp  \\\n",
       "0                  A_SUBMITTED  2011-10-01 00:38:44.546000+02:00   \n",
       "1            A_PARTLYSUBMITTED  2011-10-01 00:38:44.880000+02:00   \n",
       "2                A_PREACCEPTED  2011-10-01 00:39:37.906000+02:00   \n",
       "3       W_Completeren aanvraag  2011-10-01 00:39:38.875000+02:00   \n",
       "4       W_Completeren aanvraag  2011-10-01 11:36:46.437000+02:00   \n",
       "...                        ...                               ...   \n",
       "262195       A_PARTLYSUBMITTED  2012-02-29 23:51:17.423000+01:00   \n",
       "262196      W_Afhandelen leads  2012-02-29 23:52:01.287000+01:00   \n",
       "262197      W_Afhandelen leads  2012-03-01 09:26:46.736000+01:00   \n",
       "262198              A_DECLINED  2012-03-01 09:27:37.118000+01:00   \n",
       "262199      W_Afhandelen leads  2012-03-01 09:27:41.325000+01:00   \n",
       "\n",
       "        time:weekday  time:hour  \n",
       "0                  5          0  \n",
       "1                  5          0  \n",
       "2                  5          0  \n",
       "3                  5          0  \n",
       "4                  5         11  \n",
       "...              ...        ...  \n",
       "262195             2         23  \n",
       "262196             2         23  \n",
       "262197             3          9  \n",
       "262198             3          9  \n",
       "262199             3          9  \n",
       "\n",
       "[262200 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fix_time(time):\n",
    "    return (datetime.datetime.fromisoformat(time))\n",
    "\n",
    "def load_data(BPI = 'BPI.csv', BPI_attr = 'BPI_attr.csv',  data2012 = False):\n",
    "    df_BPI = pd.read_csv(BPI)\n",
    "    df_BPI_attr = pd.read_csv(BPI_attr)\n",
    "    \n",
    "    if 'Unnamed: 0' in df_BPI.columns:\n",
    "        df_BPI = df_BPI.rename(columns={'Unnamed: 0': 'case_id', 'Unnamed: 1': 'step_number'})\n",
    "        df_BPI_attr = df_BPI_attr.rename(columns={'Unnamed: 0': 'case_id'})\n",
    "    \n",
    "    df_BPI['time:timestamp'] = df_BPI['time:timestamp'].apply(fix_time)\n",
    "\n",
    "    if data2012:\n",
    "        df_BPI_attr['REG_DATE'] = df_BPI_attr['REG_DATE'].apply(fix_time)\n",
    "    \n",
    "    df_BPI['time:weekday'] = [x.weekday() for x in df_BPI['time:timestamp']]\n",
    "    df_BPI['time:hour'] = [x.hour for x in df_BPI['time:timestamp']]\n",
    "    return (df_BPI, df_BPI_attr)\n",
    "\n",
    "def load_data_xes(data):\n",
    "    BPI = xes_importer.apply(data)\n",
    "    \n",
    "df, df_attr = load_data(BPI = 'Datasets/BPI_2012.csv', BPI_attr = 'Datasets/BPI_attr_2012.csv', data2012 = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data splitting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(df : pd.DataFrame, amount_train_data = 0.8, amount_validation_data = 0.2) -> tuple:\n",
    "    '''Plug in the df and train and validation data percentages'''\n",
    "    \n",
    "    splitData_df = df.rename(columns={'Unnamed: 0': 'case_id', 'Unnamed: 1': 'step_number'})\n",
    "    splitData_df_attr = df_attr.rename(columns={'Unnamed: 0': 'case_id'})\n",
    "    \n",
    "    splitData_limit_date = splitData_df[splitData_df['case_id'] \n",
    "    == round(splitData_df.iloc[-1, 0]*amount_train_data)].iloc[0]['time:timestamp']\n",
    "    #splitData_limit_date = datetime.datetime(2012, 2, 3, 1, 1, 1, 633000, \n",
    "                                         #tzinfo=datetime.timezone(datetime.timedelta(seconds=7200)))\n",
    "\n",
    "    #training data_set\n",
    "    splitData_df_train = splitData_df\n",
    "    splitData_listo = []\n",
    "\n",
    "    for i in tqdm(range(0, 13087)):\n",
    "        if splitData_df[splitData_df['case_id'] == i].iloc[-1]['time:timestamp'] > splitData_limit_date:\n",
    "            splitData_listo.append(i)\n",
    "\n",
    "    for i in tqdm(range(0, len(splitData_listo))):\n",
    "        splitData_df_train = splitData_df_train.drop(splitData_df_train[splitData_df_train['case_id'] == splitData_listo[i]].index)\n",
    "\n",
    "    splitData_df_train = splitData_df_train.reset_index(drop = True)\n",
    "    \n",
    "    #validation data_set\n",
    "    mask = np.random.rand(len(splitData_df_train)) < amount_validation_data\n",
    "    splitData_df_validation = splitData_df_train[mask]\n",
    "    splitData_df_train = splitData_df_train[~mask]\n",
    "\n",
    "    #testing data_set\n",
    "    splitData_df_test = pd.DataFrame(columns = (splitData_df.columns))\n",
    "    splitData_listo = []\n",
    "\n",
    "    for i in tqdm(range(0, 13087)):\n",
    "        if splitData_df[splitData_df['case_id'] == i].iloc[0]['time:timestamp'] > splitData_limit_date:\n",
    "            splitData_listo.append(i)\n",
    "\n",
    "    for i in tqdm(range(0, len(splitData_listo))):\n",
    "        splitData_df_test = splitData_df_test.append(splitData_df[splitData_df['case_id'] == splitData_listo[i]])\n",
    "\n",
    "    splitData_df_test = splitData_df_test.reset_index(drop = True)\n",
    "    \n",
    "    return(splitData_df_train, splitData_df_validation, splitData_df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warning, the code below takes around 9 minutes to run. There will be four loading sliders in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26bc2b8f4c1d4f0aa5fcbab67710a957",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=13087.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "653ae5cfd9c846a9801bc0ae3ca49197",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=3463.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da29ee17eb0f4e0b9953aa4845bc8d38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=13087.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bc62a002adb441586308d6067b3e146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2617.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_train, df_validation, df_test = data_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('trainExample.csv')\n",
    "df_validation.to_csv('validationExample.csv')\n",
    "df_test.to_csv('testExample.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Just for usage purposes, load here the pre-created train/test sets. This is a non-release feature only for notebook swifter manipulation and shall be markdowned/deleted before submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_validation, df_test = pd.read_csv('trainExample.csv'), pd.read_csv('validationExample.csv'), pd.read_csv('testExample.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_csv(file_name : str, file_attribute_name : str) -> list:\n",
    "    '''Loading the two datasets. So far we'll only be using the BPI.csv one\n",
    "    This also parses the date column'''\n",
    "    \n",
    "    df = pd.read_csv(file_name)\n",
    "    df['time:timestamp'] = df['time:timestamp'].apply(fix_time)\n",
    "    df_attr = pd.read_csv(file_attribute_name)\n",
    "    return (df, df_attr)\n",
    "\n",
    "#Do we even need this now? def load_data is there above and they don't seen to be too different\n",
    "#I'm leaving this one so far - better not to erase in doubt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparatory work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The current version of the tool works with the 2012 dataset!!!\n",
    "baseline_df, baseline_df_attr = load_dataset_csv('Datasets/BPI_2012.csv', 'Datasets/BPI_attr_2012.csv')\n",
    "\n",
    "#Let us change the column names to the aforementioned\n",
    "def changing_columns_names(df : pd.DataFrame, data2012=True, data2017=False):\n",
    "    '''so far only works with the 2012 dataframe'''\n",
    "    \n",
    "    if(data2012):\n",
    "        df.columns = ['case_id', 'step_number', 'org:resource', 'lifecycle:transition',\n",
    "                      'concept:name', 'time:timestamp']\n",
    "    elif(data2017):\n",
    "        df.columns = ['case_id', 'step_number', 'OfferID', 'Action', 'FirstWithdrawalAmount', 'NumberOfTerms', 'Accepted', \n",
    "                      'org:resource', 'concept:name', 'MonthlyCost', 'EventOrigin', 'EventID', 'Selected', 'CreditScore', \n",
    "                      'lifecycle:transition', 'OfferedAmount', 'time:timestamp', 'time:weekday', 'time:hour']\n",
    "    \n",
    "    return(df)\n",
    "\n",
    "#Erasing all the non-complete actions from the database:\n",
    "def erasing_noncomplete(df : pd.DataFrame, data2012=True, data2017=False):\n",
    "    '''Performance depends on the type of the input dataframe'''\n",
    "    \n",
    "    if(data2012):\n",
    "        df = df[df['lifecycle:transition'] == 'COMPLETE']\n",
    "        df = df.reset_index(drop=True)\n",
    "    elif(data2017):\n",
    "        df = df[df['lifecycle:transition'] == 'complete']\n",
    "        df = df.reset_index(drop=True)\n",
    "        \n",
    "    return(df)\n",
    "\n",
    "def compute_time_difference(baseline_df : pd.DataFrame):\n",
    "    '''Set the time difference column\n",
    "    This function is places here because of the erased non-complete actions\n",
    "    \n",
    "    It has been a no-input, no-return function, so I fixed this ~ Rav'''\n",
    "\n",
    "    baseline_df['time:time_between'] = baseline_df['time:timestamp'].diff()\n",
    "    baseline_df.loc[baseline_df['step_number'] == 0, 'time:time_between'] = pd.Timedelta(0)\n",
    "    \n",
    "    return(baseline_df)\n",
    "\n",
    "def preprocessing(df, data2012=True, data2017=False):\n",
    "    '''runs the above 3 functions'''\n",
    "    \n",
    "    df = changing_columns_names(df, data2012, data2017)\n",
    "    df = erasing_noncomplete(df, data2012, data2017)\n",
    "    df = computing_time_difference(df)\n",
    "    \n",
    "    return(df)\n",
    "\n",
    "baseline_df = preprocessing(baseline_df, data2012=True, data2017=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creating_dict_for_next_step_stats (df : pd.DataFrame, concept_name : str) -> dict:\n",
    "    '''For an input action checks for all the possible next actions and counts their occurence'''\n",
    "    \n",
    "    dic_occurrence = {}\n",
    "    dic_total_time = {}\n",
    "    ids = list(df['case_id']) + ['editor: last id'] #Otherwise we check i+1-th position that does not exist\n",
    "    times = list(df['time:time_between']) + [pd.Timedelta(0)] #Otherwise we check i+1-th position that does not exist\n",
    "    names = df['concept:name']\n",
    "    df_concept = df[names == concept_name]\n",
    "    \n",
    "    for i, row in df_concept.iterrows():\n",
    "        \n",
    "        if (ids[i] == ids[i+1]): #an instance of the same case\n",
    "            \n",
    "            if (names[i+1] not in dic_occurrence):\n",
    "                dic_occurrence[names[i+1]] = 1\n",
    "                dic_total_time[names[i+1]] = times[i+1]\n",
    "            else:\n",
    "                dic_occurrence[names[i+1]] += 1\n",
    "                dic_total_time[names[i+1]] += times[i+1]\n",
    "                \n",
    "        else: #the last instance of the case\n",
    "            \n",
    "            if ('editor: close_case' not in dic_occurrence):\n",
    "                dic_occurrence['editor: close_case'] = 1\n",
    "                dic_total_time['editor: close_case'] = times[i+1]\n",
    "            else:\n",
    "                dic_occurrence['editor: close_case'] += 1\n",
    "                dic_total_time['editor: close_case'] += times[i+1]\n",
    "    \n",
    "    #Compute average time\n",
    "    dic_avg_time = {}\n",
    "    \n",
    "    for key in dic_total_time:\n",
    "        dic_avg_time[key] = dic_total_time[key] / dic_occurrence[key]\n",
    "        \n",
    "    return(dic_occurrence, dic_avg_time)\n",
    "\n",
    "creating_dict_for_next_step_stats(baseline_df, 'A_SUBMITTED')\n",
    "\n",
    "def choosing_next_action(dic : dict):\n",
    "    '''Finds the max value of the input dict and returns the key of the max value'''\n",
    "    \n",
    "    max_key = max(dic, key=dic.get)\n",
    "    return(max_key)\n",
    "\n",
    "\n",
    "def cycles_shortcut(actions : list, concept_name : str, max_length : int, printing = False) -> list or bool:\n",
    "    '''For saving the operating time, we will try to terminate the baseline early if we get into a loop\n",
    "    max_length is the longest_trace parameter'''\n",
    "    \n",
    "    if(concept_name in actions): #the action has already been done\n",
    "        \n",
    "        if(actions[-1] == concept_name): #and it's the most recent action (self-loop)\n",
    "            \n",
    "            while(len(actions) < max_length): #filling the rest of the list with the current action if we're in a self-loop\n",
    "                actions.append(concept_name)\n",
    "        \n",
    "        else: #it is not the most recent action\n",
    "            placement = actions.index(concept_name) #locating the index of the \"duplicate\"\n",
    "            aid_array = actions[placement:] #copying the values\n",
    "            if (pritning):\n",
    "#                 print(\"aid_array = \", aid_array)\n",
    "            \n",
    "            actions = actions + [0] * (max_length-len(actions)) #making [x, y, z, x] into [x, y, z, x, 0, 0, 0, ...]\n",
    "            if (printing):\n",
    "#                 print(\"actions = \", actions)\n",
    "            \n",
    "            for i in range(placement+1, max_length): #iterating only over all the indices of 0's in actions\n",
    "                actions[i] = aid_array[(i-placement)%len(aid_array)] #copying the list's values over and over again\n",
    "        \n",
    "        return(actions) #This return has to be then the return of the iterated_expected_actions\n",
    "    \n",
    "    else:\n",
    "        return(False)\n",
    "\n",
    "def iterating_expected_actions(df : pd.DataFrame, concept_name : str, n : int) -> list:\n",
    "    '''concept_name is the starting point (first action)\n",
    "    n is the length of the longest trace ever observed\n",
    "    It is stored in lonest_trace but for runtime reasons, use n so far'''\n",
    "    \n",
    "    longest_trace = max(df['step_number']) #finding the longest trace in the database (nr of steps)\n",
    "    #note that we determine this AFTER deleting some rows with uncomplete steps. We should be running this on full df\n",
    "    \n",
    "    i = 0\n",
    "    actions = [concept_name] #Here is the list that will store all the subsequent actions the algorithm decices to perform\n",
    "    while (i < n): #terminate if we are exceeding the max number of steps\n",
    "        wow = creating_dict_for_next_step_stats(df, concept_name)[0] #list all possible options\n",
    "        concept_name = choosing_next_action(wow) #Choose the most commonly used option\n",
    "        \n",
    "        if(cycles_shortcut(actions, concept_name, n) != False): #Checks if we are stuck in a loop\n",
    "            print(\"we are stuck in a loop\")\n",
    "            return(cycles_shortcut(actions, concept_name, n))\n",
    "        \n",
    "        if(concept_name == 'editor: close_case'): #If it is the \"terminate\" option - terminate\n",
    "            break\n",
    "        actions.append(concept_name) #Add the action to the list\n",
    "        i += 1\n",
    "    \n",
    "    actions.append('editor: close_case')\n",
    "    #print('i = ', i, \"n = \", n)\n",
    "    \n",
    "    return(actions)\n",
    "\n",
    "def add_expected_events(df : pd.DataFrame) -> list:\n",
    "    all_events = df['concept:name'].unique()\n",
    "    next_event_name_dic = {'editor: close_case': 'editor: close_case'}\n",
    "    next_event_duration_dic = {'editor: close_case': pd.Timedelta(0)}\n",
    "    \n",
    "    for event in all_events:\n",
    "        next_step_stats = creating_dict_for_next_step_stats(df, event)\n",
    "        wow = next_step_stats[0] #list all possible options\n",
    "        concept_name = choosing_next_action(wow) #Choose the most commonly used option\n",
    "        next_event_name_dic[event] = concept_name\n",
    "        next_event_duration_dic[event] = next_step_stats[1][concept_name]\n",
    "    \n",
    "    return next_event_name_dic, next_event_duration_dic\n",
    "\n",
    "#Get list of all expected next events and the expected time till that next event\n",
    "baseline_all_expected_events = add_expected_events(baseline_df)\n",
    "\n",
    "#Add column to dataframe with expected next events and times\n",
    "baseline_df['expect:next_event'] = baseline_df['concept:name'].map(baseline_all_expected_events[0])\n",
    "baseline_df['expect:next_time'] = baseline_df['concept:name'].map(baseline_all_expected_events[1]) + baseline_df['time:timestamp']\n",
    "\n",
    "baseline_df.to_csv('BPI_with_predictions.csv')\n",
    "\n",
    "iterating_expected_actions(baseline_df, 'A_SUBMITTED', 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline's performance testing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set sample datasets of the below sizes to test the runtime of any algorithm on them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_limits = [50, 100, 200, 500, 1000, 2000, 5000, 10000, 20000, 50000, 100000]\n",
    "baseline_runtimes = [0] * len(baseline_limits)\n",
    "\n",
    "for i in range(0, len(baseline_limits)):\n",
    "    print(i)\n",
    "    df_small = baseline_df[:baseline_limits[i]]\n",
    "    time_start = time.time()\n",
    "    iterating_expected_actions(df_small, 'A_SUBMITTED', 15)\n",
    "    time_end = time.time()\n",
    "    baseline_runtimes[i] = time_end-time_start\n",
    "    \n",
    "baseline_runtimes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting its runtimes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_wow = plt.figure(figsize=(7.5, 5))\n",
    "plt.scatter(x = baseline_limits, y=baseline_runtimes, color = '#AB3334')\n",
    "plt.title('Runtime of the baseline algorithm (log scale)', fontsize = 16)\n",
    "plt.ylabel('Operating time [log(s)]', fontsize = 13)\n",
    "plt.xlabel('Input size [log(n)]', fontsize = 13)\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale('log')\n",
    "\n",
    "baseline_wow2 = plt.figure(figsize=(7.5, 5))\n",
    "plt.scatter(x = baseline_limits, y=baseline_runtimes, color = '#420CDA')\n",
    "plt.title('Runtime of the baseline algorithm', fontsize = 16)\n",
    "plt.ylabel('Operating time [s]', fontsize = 13)\n",
    "plt.xlabel('Input size [n]', fontsize = 13)\n",
    "\n",
    "baseline_f, (ax1, ax2) = plt.subplots(1, 2, figsize=(18,6))\n",
    "\n",
    "ax1.scatter(x = baseline_limits, y=baseline_runtimes, color = '#420CDA')\n",
    "ax1.set_title('Runtime of the baseline algorithm', fontsize = 16)\n",
    "ax1.set_xlabel('Input size [n]', fontsize = 13)\n",
    "ax1.set_ylabel('Operating time [s]', fontsize = 13)\n",
    "\n",
    "ax2.scatter(x = baseline_limits, y=baseline_runtimes, color = '#AB3334')\n",
    "ax2.set_title('Runtime of the baseline algorithm (log scale)', fontsize = 16)\n",
    "ax2.set_ylabel('Operating time [log(s)]', fontsize = 13)\n",
    "ax2.set_xlabel('Input size [log(n)]', fontsize = 13)\n",
    "ax2.set_xscale(\"log\")\n",
    "ax2.set_yscale('log')\n",
    "\n",
    "baseline_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing the accuracy of predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing the Baseline\n",
    "testingBaseline_df, testingBaseline_df_attr = load_data(BPI = 'Datasets/BPI_2012.csv', BPI_attr = 'Datasets/BPI_attr_2012.csv', data2012 = True)\n",
    "testingBaseline_df, testingBaseline_df_attr = preprocessing(testingBaseline_df), preprocessing(testingBaseline_df_attr)\n",
    "\n",
    "#Couldn't you re-use the data_split function here, Sven?\n",
    "#Also, tqdm iterates exactly over 13087 rows here, why is it so? Won't this be incompatible with non-2012 data?\n",
    "\n",
    "\n",
    "#amount of total data that is training data:\n",
    "testingBaseline_train_data = 0.8\n",
    "#amount of train data that is validation data:\n",
    "testingBaseline_validation_data = 0.1\n",
    "\n",
    "testingBaseline_limit_date = testingBaseline_df[testingBaseline_df['case_id'] == round(testingBaseline_df.iloc[-1, 0]*testingBaseline_train_data)].iloc[0]['time:timestamp']\n",
    "#limit_date = datetime.datetime(2012, 2, 3, 1, 1, 1, 633000, tzinfo=datetime.timezone(datetime.timedelta(seconds=7200))) \n",
    "\n",
    "#training data_set\n",
    "testingBaseline_df_train = testingBaseline_df\n",
    "testingBaseline_listo = []\n",
    "\n",
    "for i in tqdm(range(0, 13087)):\n",
    "    if testingBaseline_df[testingBaseline_df['case_id'] == i].iloc[-1]['time:timestamp'] > testingBaseline_limit_date:\n",
    "        testingBaseline_listo.append(i)\n",
    "\n",
    "for i in tqdm(range(0, len(testingBaseline_listo))):\n",
    "    testingBaseline_df_train = testingBaseline_df_train.drop(testingBaseline_df_train[testingBaseline_df_train['case_id']==testingBaseline_listo[i]].index)\n",
    "\n",
    "testingBaseline_df_train = testingBaseline_df_train.reset_index(drop = True)\n",
    "\n",
    "#splitting training dataset into validation and training dataset\n",
    "testingBaseline_mask = np.random.rand(len(testingBaseline_df_train)) < testingBaseline_validation_data\n",
    "testingBaseline_df_validation = testingBaseline_df_train[testingBaseline_mask]\n",
    "testingBaseline_df_train = testingBaseline_df_train[~testingBaseline_mask]\n",
    "\n",
    "#testing data_set\n",
    "testingBaseline_df_test = pd.DataFrame(columns = (testingBaseline_df.columns))\n",
    "testingBaseline_listo = []\n",
    "\n",
    "for i in tqdm(range(0, 13087)):\n",
    "    if testingBaseline_df[testingBaseline_df['case_id'] == i].iloc[0]['time:timestamp'] > testingBaseline_limit_date:\n",
    "        testingBaseline_listo.append(i)\n",
    "\n",
    "for i in tqdm(range(0, len(testingBaseline_listo))):\n",
    "    testingBaseline_df_test = testingBaseline_df_test.append(testingBaseline_df[testingBaseline_df['case_id'] == testingBaseline_listo[i]])\n",
    "\n",
    "testingBaseline_df_test = testingBaseline_df_test.reset_index(drop = True)\n",
    "\n",
    "testingBaseline_df_train.to_csv('BPI_2012_train', index=False)\n",
    "\n",
    "testingBaseline_df_validation.to_csv('BPI_2012_validation')\n",
    "\n",
    "testingBaseline_df_test.to_csv('BPI_2012_test', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testingBaseline_df_train = pd.read_csv('BPI_2012_train')\n",
    "testingBaseline_df_train['time:timestamp'] = testingBaseline_df_train['time:timestamp'].apply(fix_time)\n",
    "testingBaseline_df_train['time:time_between'] = testingBaseline_df_train['time:timestamp'].diff()\n",
    "testingBaseline_df_train.loc[testingBaseline_df['step_number'] == 0, 'time:time_between'] = pd.Timedelta(0)\n",
    "\n",
    "testingBaseline_df_test = pd.read_csv('BPI_2012_test')\n",
    "testingBaseline_df_test['time:timestamp'] = testingBaseline_df_test['time:timestamp'].apply(fix_time)\n",
    "testingBaseline_df_test['time:time_between'] = testingBaseline_df_test['time:timestamp'].diff()\n",
    "testingBaseline_df_test.loc[testingBaseline_df['step_number'] == 0, 'time:time_between'] = pd.Timedelta(0)\n",
    "\n",
    "#creates column with predicted data\n",
    "def prediction(prev):\n",
    "    return baseline_all_expected_events[0][prev]\n",
    "\n",
    "testingBaseline_df_test['predicted'] = testingBaseline_df_test['concept:name'].apply(prediction)\n",
    "\n",
    "#function that creates the 'correct' using a dataframe, the predcting column and the true column, it shows wether the prediction was correct\n",
    "testingBaseline_df_test['shifted_actual'] = testingBaseline_df_test['concept:name'].shift(-1)\n",
    "testingBaseline_df_test['shifted_case_id'] = testingBaseline_df_test['case_id'].shift(-1)\n",
    "    \n",
    "def apply_function(var):\n",
    "    if var[2] == var[3]:\n",
    "        return (var[0] == var[1])\n",
    "        \n",
    "    else:\n",
    "        return (var[0] == 'editor:close_case')\n",
    "        \n",
    "testingBaseline_df_test['correct'] = testingBaseline_df_test[['predicted', 'shifted_actual', 'case_id', 'shifted_case_id']].apply(apply_function, axis=1)\n",
    "testingBaseline_df_test = testingBaseline_df_test.drop(['shifted_actual', 'shifted_case_id'], axis=1)\n",
    "\n",
    "def prediction(prev):\n",
    "    return baseline_all_expected_events[1][prev]\n",
    "\n",
    "testingBaseline_df_test['time:between_predicted'] = testingBaseline_df_test['concept:name'].apply(prediction)\n",
    "\n",
    "#create column with absolute difference between predicted time and actual time\n",
    "def time_difference(var):\n",
    "    return abs((var[0] - var[1]).total_seconds())\n",
    "\n",
    "def time_difference_if_correct(var):\n",
    "    if var[0]:\n",
    "        return abs((var[1] - var[2]).total_seconds())\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "testingBaseline_df_test['time:absolute_predicton_off'] = testingBaseline_df_test[['time:time_between', 'time:between_predicted']].apply(time_difference, axis=1)\n",
    "testingBaseline_df_test['time:absolute_predicton_correct'] = testingBaseline_df_test[['correct', 'time:time_between', 'time:between_predicted']].apply(time_difference_if_correct, axis=1)\n",
    "    \n",
    "\n",
    "testingBaseline_df_test['time:relative_predicton_off'] = testingBaseline_df_test[['time:time_between', 'time:between_predicted']].apply(time_difference, axis=1)\n",
    "testingBaseline_df_test['time:relative_predicton_correct'] = testingBaseline_df_test[['correct', 'time:time_between', 'time:between_predicted']].apply(time_difference_if_correct, axis=1)\n",
    "\n",
    "\n",
    "#THERE IS A FUNCTION TIMELY_STATISTICS BELOW THAT DOES EXACTLY THAT! \n",
    "#FIND IT, BEING IT HERE, CHANGE THE PARAMETER AND REDUCE THE NUMBER OF LINES HERE (to do: Rav)\n",
    "#mean of the absolute time\n",
    "seconds = testingBaseline_df_test['time:absolute_predicton_off'].mean()\n",
    "minutes = seconds/60\n",
    "hours = minutes/60\n",
    "days = hours/24\n",
    "print(str(seconds) + ', ' + str(minutes) + ', ' + str(hours) + ', ' + str(days))\n",
    "\n",
    "seconds = testingBaseline_df_test['time:absolute_predicton_correct'].mean()\n",
    "minutes = seconds/60\n",
    "hours = minutes/60\n",
    "days = hours/24\n",
    "print(str(seconds) + ', ' + str(minutes) + ', ' + str(hours) + ', ' + str(days))\n",
    "\n",
    "#median of the absolute time\n",
    "seconds = testingBaseline_df_test['time:absolute_predicton_off'].median()\n",
    "minutes = seconds/60\n",
    "hours = minutes/60\n",
    "days = hours/24\n",
    "print(str(seconds) + ', ' + str(minutes) + ', ' + str(hours) + ', ' + str(days))\n",
    "\n",
    "seconds = testingBaseline_df_test['time:absolute_predicton_correct'].median()\n",
    "minutes = seconds/60\n",
    "hours = minutes/60\n",
    "days = hours/24\n",
    "print(str(seconds) + ', ' + str(minutes) + ', ' + str(hours) + ', ' + str(days))\n",
    "\n",
    "testingBaseline_df_test['time:absolute_predicton_off'].hist(bins=10)\n",
    "\n",
    "#mean of the relative time\n",
    "seconds = testingBaseline_df_test['time:relative_predicton_off'].mean()\n",
    "minutes = seconds/60\n",
    "hours = minutes/60\n",
    "days = hours/24\n",
    "print(str(seconds) + ', ' + str(minutes) + ', ' + str(hours) + ', ' + str(days))\n",
    "\n",
    "seconds = testingBaseline_df_test['time:relative_predicton_correct'].mean()\n",
    "minutes = seconds/60\n",
    "hours = minutes/60\n",
    "days = hours/24\n",
    "print(str(seconds) + ', ' + str(minutes) + ', ' + str(hours) + ', ' + str(days))\n",
    "\n",
    "#median of the relative time\n",
    "seconds = testingBaseline_df_test['time:relative_predicton_off'].median()\n",
    "minutes = seconds/60\n",
    "hours = minutes/60\n",
    "days = hours/24\n",
    "print(str(seconds) + ', ' + str(minutes) + ', ' + str(hours) + ', ' + str(days))\n",
    "\n",
    "seconds = testingBaseline_df_test['time:relative_predicton_correct'].median()\n",
    "minutes = seconds/60\n",
    "hours = minutes/60\n",
    "days = hours/24\n",
    "print(str(seconds) + ', ' + str(minutes) + ', ' + str(hours) + ', ' + str(days))\n",
    "\n",
    "testingBaseline_df_test['time:relative_predicton_off'].hist(bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "NR_OF_CLUSTERS = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_column_for_clustering(case_id_column, cluster_column, unique_values):\n",
    "    grouped_df = pd.DataFrame({'case_id': case_id_column, 'column': cluster_column})\n",
    "    \n",
    "    for val in unique_values:\n",
    "        grouped_df[val] = 0\n",
    "        grouped_df.loc[grouped_df['column'] == val, val] = 1\n",
    "    \n",
    "    return grouped_df[['case_id'] + list(unique_values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clusters(prepared_rows):\n",
    "    kmeans = KMeans(n_clusters=NR_OF_CLUSTERS)\n",
    "    \n",
    "    unique_columns = list(prepared_rows.columns)\n",
    "    unique_columns.pop(0)\n",
    "\n",
    "    df_grouped = prepared_rows.groupby('case_id')[unique_columns].sum()\n",
    "    kmeans.fit(df_grouped[unique_columns])\n",
    "    prediction = kmeans.labels_\n",
    "    unique_case_ids = prepared_rows['case_id'].unique()\n",
    "    return prepared_rows.case_id.map({unique_case_ids[i]: prediction[i] for i in range(len(prediction))}), kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tree(df_train, clusters, mapping):\n",
    "    model = RandomForestClassifier(n_estimators=100, max_depth=10)\n",
    "    special_df = df_train.copy()\n",
    "    \n",
    "    special_df['next_event int'] = special_df['next_event'].map(mapping)\n",
    "    \n",
    "    X_dtc = special_df[clusters + ['step_number', 'time:weekday', 'time:hour']].copy()\n",
    "    y_dtc = special_df[['next_event int']]\n",
    "\n",
    "    model.fit(X_dtc, y_dtc['next_event int'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_clusters(cluster_model, prepared_rows, unique_columns):\n",
    "    df_grouped = prepared_rows.groupby('case_id')[unique_columns].sum()\n",
    "    prediction = cluster_model.predict(df_grouped[unique_columns])\n",
    "    unique_case_ids = prepared_rows['case_id'].unique()\n",
    "    return prepared_rows.case_id.map({unique_case_ids[i]: prediction[i] for i in range(len(prediction))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_value(tree, df_predict, clusters, reverse_mapping):\n",
    "    X_dtc = df_predict[clusters + ['step_number', 'time:weekday', 'time:hour']]\n",
    "    \n",
    "    prediction = tree.predict(X_dtc)\n",
    "    return np.vectorize(reverse_mapping.get)(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-da23c3f1d6ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcluster_tree_test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m \u001b[0mcluster_tree_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;31m#use df_train for the train, df_validation for testing the parameters and df_test for testing the final result.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-31-da23c3f1d6ee>\u001b[0m in \u001b[0;36mcluster_tree_predict\u001b[1;34m(df_train, df_test)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mclustered_train_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m                 \u001b[0mtree_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclustered_train_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0massigned_columns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mclustered_test_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-4b11c7740206>\u001b[0m in \u001b[0;36mget_tree\u001b[1;34m(df_train, clusters, mapping)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0my_dtc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspecial_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'next_event int'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_dtc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_dtc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'next_event int'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    390\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m                     n_samples_bootstrap=n_samples_bootstrap)\n\u001b[1;32m--> 392\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1049\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    864\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 866\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    867\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    782\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    783\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 784\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    785\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 263\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 263\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m         indices = _generate_sample_indices(tree.random_state, n_samples,\n\u001b[1;32m--> 155\u001b[1;33m                                            n_samples_bootstrap)\n\u001b[0m\u001b[0;32m    156\u001b[0m         \u001b[0msample_counts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminlength\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[0mcurr_sample_weight\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0msample_counts\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_generate_sample_indices\u001b[1;34m(random_state, n_samples, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[0mrandom_instance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m     \u001b[0msample_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom_instance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_samples_bootstrap\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msample_indices\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def cluster_tree_predict(df_train, df_test):\n",
    "    cluster_tree_train, cluster_tree_test = df_train.copy(), df_test.copy()\n",
    "    \n",
    "    cluster_tree_train[\"next_event\"] = cluster_tree_train[\"concept:name\"]\n",
    "    cluster_tree_train.loc[cluster_tree_train['step_number'] == 0, 'next_event'] = 'editor: close_case'\n",
    "    cluster_tree_train[\"next_event\"] = cluster_tree_train[\"next_event\"].shift(-1)\n",
    "    cluster_tree_train.loc[len(cluster_tree_train) - 1, 'next_event'] = 'editor: close_case'\n",
    "    \n",
    "    cluster_tree_test[\"next_event\"] = cluster_tree_test[\"concept:name\"]\n",
    "    cluster_tree_test.loc[cluster_tree_test['step_number'] == 0, 'next_event'] = 'editor: close_case'\n",
    "    cluster_tree_test[\"next_event\"] = cluster_tree_test[\"next_event\"].shift(-1)\n",
    "    cluster_tree_test.loc[len(cluster_tree_test) - 1, 'next_event'] = 'editor: close_case'\n",
    "    \n",
    "    mapping, reverse_mapping = {}, {}\n",
    "    all_events = ['editor: close_case'] + list(cluster_tree_train['concept:name'].unique())\n",
    "\n",
    "    for i in range(len(all_events)):\n",
    "        mapping[all_events[i]] = i\n",
    "        reverse_mapping[i] = all_events[i]\n",
    "    \n",
    "    #Clustering\n",
    "    cluster_columns = ['concept:name', 'org:resource'] # ENTER CLUSTER COLUMN NAMES (max 2) HERE\n",
    "    assigned_columns = [cluster_columns[i] + ' cluster' for i in range(len(cluster_columns))]\n",
    "    \n",
    "    for i in range(len(cluster_columns)):\n",
    "        #Make sure no NaN values exist in these columns\n",
    "        cluster_tree_train[cluster_columns[i]] = cluster_tree_train[cluster_columns[i]].fillna(-1)\n",
    "        cluster_tree_test[cluster_columns[i]] = cluster_tree_test[cluster_columns[i]].fillna(-1)\n",
    "        \n",
    "        unique_values = cluster_tree_train[cluster_columns[i]].unique()\n",
    "        prepared_train_data = prepare_column_for_clustering(cluster_tree_train['case_id'], cluster_tree_train[cluster_columns[i]], unique_values)\n",
    "        cluster_tree_train[assigned_columns[i]], cluster_model = get_clusters(prepared_train_data)\n",
    "\n",
    "        prepared_test_data = prepare_column_for_clustering(cluster_tree_test['case_id'], cluster_tree_test[cluster_columns[i]], unique_values)\n",
    "        cluster_tree_test[assigned_columns[i]] = predict_clusters(cluster_model, prepared_test_data, unique_values)\n",
    "        \n",
    "    \n",
    "    for j in range(NR_OF_CLUSTERS):\n",
    "        next_amount = NR_OF_CLUSTERS\n",
    "        if len(cluster_columns) == 1:\n",
    "            next_amount = 1\n",
    "        for i in range(next_amount):\n",
    "            if len(cluster_columns) == 1:\n",
    "                clustered_train_df = cluster_tree_train[cluster_tree_train[assigned_columns[0]] == i]\n",
    "                clustered_test_df = cluster_tree_test[cluster_tree_test[assigned_columns[0]] == i]\n",
    "            else:\n",
    "                clustered_train_df = cluster_tree_train[(cluster_tree_train[assigned_columns[0]] == i) & (cluster_tree_test[assigned_columns[1]] == j)]\n",
    "                clustered_test_df = cluster_tree_test[(cluster_tree_test[assigned_columns[0]] == i) & (cluster_tree_test[assigned_columns[1]] == j)]\n",
    "        \n",
    "            if clustered_train_df.size > 0:\n",
    "                tree_model = get_tree(clustered_train_df, assigned_columns, mapping)\n",
    "        \n",
    "                if clustered_test_df.size > 0:\n",
    "                    if len(cluster_columns) == 1:\n",
    "                        cluster_tree_test.loc[cluster_tree_test[assigned_columns[0]] == i, 'prediction'] = predict_value(tree_model, clustered_test_df, assigned_columns, reverse_mapping)\n",
    "                    else:\n",
    "                        cluster_tree_test.loc[(cluster_tree_test[assigned_columns[0]] == i) & (cluster_tree_test[assigned_columns[1]] == j), 'prediction'] = predict_value(tree_model, clustered_test_df, assigned_columns, reverse_mapping)\n",
    "    \n",
    "    return cluster_tree_test\n",
    "    \n",
    "cluster_tree_predict(df_train, df_test)\n",
    "#use df_train for the train, df_validation for testing the parameters and df_test for testing the final result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model testing using test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I used tree as a standin for the df_test result, this can be changed later\n",
    "df_tree = cluster_tree_predict(df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 53.3%\n"
     ]
    }
   ],
   "source": [
    "#prints accuracy of the tree dataset\n",
    "accuracy = round((len(df_tree[df_tree['next_event'] == df_tree['prediction']])/len(df_tree))*100, 1)\n",
    "print('accuracy: ' + str(accuracy) + '%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_PARTLYSUBMITTED\n",
      "85.5%\n",
      "given 14.5% too little\n",
      "\n",
      "A_PREACCEPTED\n",
      "68.8%\n",
      "given 31.2% too little\n",
      "\n",
      "W_Completeren aanvraag\n",
      "130.9%\n",
      "given 30.9% too much\n",
      "\n",
      "editor: close_case\n",
      "82.3%\n",
      "given 17.7% too little\n",
      "\n",
      "A_DECLINED\n",
      "77.5%\n",
      "given 22.5% too little\n",
      "\n",
      "A_ACCEPTED\n",
      "36.1%\n",
      "given 63.9% too little\n",
      "\n",
      "A_FINALIZED\n",
      "35.4%\n",
      "given 64.6% too little\n",
      "\n",
      "O_SELECTED\n",
      "33.5%\n",
      "given 66.5% too little\n",
      "\n",
      "O_CREATED\n",
      "44.6%\n",
      "given 55.4% too little\n",
      "\n",
      "W_Nabellen offertes\n",
      "142.2%\n",
      "given 42.2% too much\n",
      "\n",
      "O_SENT\n",
      "28.6%\n",
      "given 71.4% too little\n",
      "\n",
      "W_Valideren aanvraag\n",
      "87.6%\n",
      "given 12.4% too little\n",
      "\n",
      "O_SENT_BACK\n",
      "56.4%\n",
      "given 43.6% too little\n",
      "\n",
      "W_Nabellen incomplete dossiers\n",
      "140.7%\n",
      "given 40.7% too much\n",
      "\n",
      "W_Afhandelen leads\n",
      "80.8%\n",
      "given 19.2% too little\n",
      "\n",
      "O_CANCELLED\n",
      "19.8%\n",
      "given 80.2% too little\n",
      "\n",
      "A_APPROVED\n",
      "22.9%\n",
      "given 77.1% too little\n",
      "\n",
      "O_ACCEPTED\n",
      "26.1%\n",
      "given 73.9% too little\n",
      "\n",
      "A_REGISTERED\n",
      "12.8%\n",
      "given 87.2% too little\n",
      "\n",
      "A_CANCELLED\n",
      "19.8%\n",
      "given 80.2% too little\n",
      "\n",
      "A_ACTIVATED\n",
      "18.7%\n",
      "given 81.3% too little\n",
      "\n",
      "W_Beoordelen fraude\n",
      "63.6%\n",
      "given 36.4% too little\n",
      "\n",
      "O_DECLINED\n",
      "19.4%\n",
      "given 80.6% too little\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#shows which predictions are given too much (>1) and which too little (<1)\n",
    "predicted_correct_events = Counter(list(df_tree[df_tree['next_event'] == df_tree['prediction']]['prediction']))\n",
    "predicted_events = Counter(list(df_tree['prediction']))\n",
    "true_events = Counter(list(df_tree['next_event']))\n",
    "\n",
    "for i in predicted_events:\n",
    "    if i != i:\n",
    "        break\n",
    "    print(i)\n",
    "    per = round(predicted_events[i]/true_events[i]*100, 1)\n",
    "    print(str(per) + '%')\n",
    "    if per > 100:\n",
    "        print('given ' + str(round(per-100, 1)) + '% too much')\n",
    "    \n",
    "    elif per < 100:\n",
    "        print('given ' + str(round(100-per, 1)) + '% too little')\n",
    "    \n",
    "    else:\n",
    "        print('given exactly the right amount')\n",
    "   \n",
    "    print('')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_tree' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-b98cd7b38243>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mdf_tree\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'time:absolute_predicton_off'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_tree\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'time:time_between'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'time:between_predicted'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime_difference\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mdf_tree\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'time:absolute_predicton_correct'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_tree\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'correct'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'time:time_between'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'time:between_predicted'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime_difference_if_correct\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_tree' is not defined"
     ]
    }
   ],
   "source": [
    "#shows time related attributes of tree (assuming that time is stored in 'time:between_predicted')\n",
    "#create column with absolute difference between predicted time and actual time\n",
    "def time_difference(var):\n",
    "    return abs((var[0] - var[1]).total_seconds())\n",
    "\n",
    "def time_difference_if_correct(var):\n",
    "    if var[0]:\n",
    "        return abs((var[1] - var[2]).total_seconds())\n",
    "    else:\n",
    "        return (0)\n",
    "\n",
    "df_tree['time:absolute_predicton_off'] = df_tree[['time:time_between', 'time:between_predicted']].apply(time_difference, axis=1)\n",
    "df_tree['time:absolute_predicton_correct'] = df_tree[['correct', 'time:time_between', 'time:between_predicted']].apply(time_difference_if_correct, axis=1)\n",
    "    \n",
    "\n",
    "df_tree['time:relative_predicton_off'] = df_tree[['time:time_between', 'time:between_predicted']].apply(time_difference, axis=1)\n",
    "df_tree['time:relative_predicton_correct'] = df_tree[['correct', 'time:time_between', 'time:between_predicted']].apply(time_difference_if_correct, axis=1)\n",
    "\n",
    "def timely_statistics(df_tree : pd.DataFrame, relative : bool, statistic : str) -> None:\n",
    "    '''I automated the prints below ~ Rav'''\n",
    "    \n",
    "    if(statistic == 'mean' and relative == False):\n",
    "        seconds1, seconds2 = df_tree['time:absolute_prediction_off'].mean(), df_tree['time:absolute_prediction_correct'].mean()\n",
    "        minutes1, hours1, days1, minutes2, hours2, days2 = seconds1/60, seconds1/3600, seconds1/86400, seconds2/60, seconds2/3600, seconds2/86400\n",
    "        print('absolute off mean: ' + str(seconds1) + ', ' + str(minutes1) + ', ' + str(hours1) + ', ' + str(days1))\n",
    "        print('absolute correct mean: ' + str(seconds2) + ', ' + str(minutes2) + ', ' + str(hours2) + ', ' + str(days2))\n",
    "        \n",
    "    if(statistic == 'median' and relative == False):\n",
    "        seconds1, seconds2 = df_tree['time:absolute_prediction_off'].median(), df_tree['time:absolute_prediction_correct'].median()\n",
    "        minutes1, hours1, days1, minutes2, hours2, days2 = seconds1/60, seconds1/3600, seconds1/86400, seconds2/60, seconds2/3600, seconds2/86400\n",
    "        print('absolute off median: ' + str(seconds1) + ', ' + str(minutes1) + ', ' + str(hours1) + ', ' + str(days1))\n",
    "        print('absolute correct median: ' + str(seconds2) + ', ' + str(minutes2) + ', ' + str(hours2) + ', ' + str(days2))\n",
    "        \n",
    "    if(statistic == 'mean' and relative==True):\n",
    "        df_tree['time:absolute_predicton_off'].hist(bins=10)\n",
    "        seconds1, seconds2 = df_tree['time:relative_prediction_off'].mean(), df_tree['time:relative_prediction_correct'].mean()\n",
    "        minutes1, hours1, days1, minutes2, hours2, days2 = seconds1/60, seconds1/3600, seconds1/86400, seconds2/60, seconds2/3600, seconds2/86400\n",
    "        print('relative off mean: ' + str(seconds1) + ', ' + str(minutes1) + ', ' + str(hours1) + ', ' + str(days1))\n",
    "        print('relative correct mean: ' + str(seconds2) + ', ' + str(minutes2) + ', ' + str(hours2) + ', ' + str(days2))\n",
    "        \n",
    "    if(statistic == 'median' and relative==True):\n",
    "        df_tree['time:absolute_predicton_off'].hist(bins=10)\n",
    "        seconds1, seconds2 = df_tree['time:relative_prediction_off'].median(), df_tree['time:relative_prediction_correct'].median()\n",
    "        minutes1, hours1, days1, minutes2, hours2, days2 = seconds1/60, seconds1/3600, seconds1/86400, seconds2/60, seconds2/3600, seconds2/86400\n",
    "        print('relative off median: ' + str(seconds1) + ', ' + str(minutes1) + ', ' + str(hours1) + ', ' + str(days1))\n",
    "        print('relative correct median: ' + str(seconds2) + ', ' + str(minutes2) + ', ' + str(hours2) + ', ' + str(days2))\n",
    "        \n",
    "for element in [(True, 'mean'), (True, 'median'), (False, 'mean'), (False, 'median')]:\n",
    "    timely_statistics(df_tree, relative=element[0], ststistic=element[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from random import randint\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group pre-cluster df by case (case_id)\n",
    "precluster_df = prepare_column_for_clustering(df['case_id'], df['concept:name'], df['concept:name'].unique())\n",
    "precluster_df_by_case = precluster_df.groupby('case_id').sum()\n",
    "precluster_df_by_case.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform PCA (2 component) on the data\n",
    "pca = PCA(n_components = 2)\n",
    "pca.fit(precluster_df_by_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create principle components\n",
    "pca_df = pd.DataFrame(pca.transform(precluster_df_by_case))\n",
    "pca_df.index.names = ['case_id']\n",
    "pca_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['concept:name cluster'], cluster_model = get_clusters(precluster_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group regular df by case (case_id)\n",
    "df_by_case = df.groupby('case_id').mean()[['concept:name cluster']]\n",
    "df_by_case.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge the dataframes\n",
    "vis_df = pd.merge(df_by_case, pca_df, on='case_id', how='left')\n",
    "vis_df.columns = ['cluster', 'x_comp', 'y_comp']\n",
    "vis_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot with low alpha\n",
    "sns.lmplot('x_comp', 'y_comp', data=vis_df, hue='cluster', fit_reg=False, height=8, aspect=2, scatter_kws={'alpha': 0.05});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot with high alpha\n",
    "sns.lmplot('x_comp', 'y_comp', data=vis_df, hue='cluster', fit_reg=False, height=8, aspect=2, scatter_kws={'alpha': 0.9});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
